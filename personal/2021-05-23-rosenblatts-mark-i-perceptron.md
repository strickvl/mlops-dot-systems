---
author: Alex Strick van Linschoten
categories:
  - tech
  - coding
  - useful-tools
  - deep-learning
  - technology
  - deeplearning
date: "2021-05-23"
description: "I learned about Rosenblatt's Mark I Perceptron, the 1958 machine that pioneered artificial neural networks and how Minsky and Papert's critique inadvertently triggered the first AI winter."
layout: post
title: "Rosenblatt's Mark I Perceptron"
toc: true
aliases:
  - "/blog/rosenblatts-mark-i-perceptron.html"
comments:
  utterances:
    repo: strickvl/mlops-dot-systems
---

I've now read a little about Rosenblatt's Perceptron in two different places: in the [Howard/Gugger Deep Learning book](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527/ref=sr_1_1?dchild=1&qid=1621784082&keywords=deep%252Blearning%252Bfor%252Bcoders&tag=soumet-20&sr=8-1), and also in Cade Metz' [Genius Makers](https://www.amazon.com/Genius-Makers-Mavericks-Brought-Facebook-ebook/dp/B08CD1M43L/ref=sr_1_1?sr=8-1&tag=soumet-20&keywords=genius%2Bmakers&dchild=1&qid=1621785566).

![The Mark I Perceptron](https://upload.wikimedia.org/wikipedia/en/5/52/Mark_I_perceptron.jpeg)

Built in 1958, it is usually described as the first machine which was based on the principle of the artificial neutron. It used a single layer in this initial configuration, and even in that simple way you could already see glimpses of where it might go.

Unfortunately, Marvin Minsky and Seymour Papert's apparently perceptive but also damning [assessment of the perceptron](https://www.amazon.com/Perceptrons-Introduction-Computational-Geometry-Expanded/dp/0262631113/ref=sr_1_1?sr=8-1&tag=soumet-20&keywords=minsky%2Bperceptron&dchild=1&qid=1621785922) as a technology without a future ushered in the first of the so-called 'AI winters', and the idea of using neural networks was buried for several years.

Thankfully, some ignored the herd and stuck with it.
