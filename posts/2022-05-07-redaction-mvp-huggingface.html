<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Alex Strick van Linschoten">
<meta name="dcterms.date" content="2022-05-07">
<meta name="description" content="I created a few deployed MVP demos showcasing models I‚Äôd created while participating in the fastai course, uploading them to the Huggingface Hub and using a Gradio Demo hosted on Huggingface Spaces.">

<title>Alex Strick van Linschoten - A painless way to create an MVP demo using computer vision models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script defer="" data-domain="mlops.systems" src="https://plausible.io/js/script.js"></script>


<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="Alex Strick van Linschoten - A painless way to create an MVP demo using computer vision models">
<meta property="og:description" content="I created a few deployed MVP demos showcasing models I'd created while participating in the fastai course, uploading them to the Huggingface Hub and using a Gradio Demo hosted on Huggingface Spaces.">
<meta property="og:image" content="https://mlops.systems/posts/redaction-mvp-huggingface/demo-screenshot.png">
<meta property="og:site-name" content="Alex Strick van Linschoten">
<meta property="og:image:height" content="565">
<meta property="og:image:width" content="700">
<meta name="twitter:title" content="Alex Strick van Linschoten - A painless way to create an MVP demo using computer vision models">
<meta name="twitter:description" content="I created a few deployed MVP demos showcasing models I'd created while participating in the fastai course, uploading them to the Huggingface Hub and using a Gradio Demo hosted on Huggingface Spaces.">
<meta name="twitter:image" content="https://mlops.systems/posts/redaction-mvp-huggingface/demo-screenshot.png">
<meta name="twitter:creator" content="@strickvl">
<meta name="twitter:image-height" content="565">
<meta name="twitter:image-width" content="700">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Alex Strick van Linschoten</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../til.html">
 <span class="menu-text">TIL</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/strickvl"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://sigmoid.social/web/@alexstrick"><i class="bi bi-mastodon" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/strickvl"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://mlops.systems/index.xml"><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">A painless way to create an MVP demo using computer vision models</h1>
                  <div>
        <div class="description">
          I created a few deployed MVP demos showcasing models I‚Äôd created while participating in the fastai course, uploading them to the Huggingface Hub and using a Gradio Demo hosted on Huggingface Spaces.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">fastai</div>
                <div class="quarto-category">computervision</div>
                <div class="quarto-category">redactionmodel</div>
                <div class="quarto-category">tools</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Alex Strick van Linschoten </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 7, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#motivation" id="toc-motivation" class="nav-link active" data-scroll-target="#motivation">üö¶ Motivation</a></li>
  <li><a href="#step-by-step-iteration-by-iteration" id="toc-step-by-step-iteration-by-iteration" class="nav-link" data-scroll-target="#step-by-step-iteration-by-iteration">üêæ Step by step, iteration by iteration</a></li>
  <li><a href="#using-the-inference-api-for-more-flexibility" id="toc-using-the-inference-api-for-more-flexibility" class="nav-link" data-scroll-target="#using-the-inference-api-for-more-flexibility">‚ö°Ô∏è Using the inference API for more flexibility</a></li>
  <li><a href="#building-an-mvp-of-a-redaction-detection-application" id="toc-building-an-mvp-of-a-redaction-detection-application" class="nav-link" data-scroll-target="#building-an-mvp-of-a-redaction-detection-application">üöÄ Building an MVP of a redaction detection application</a></li>
  <li><a href="#converting-a-gradio-app-over-to-streamlit" id="toc-converting-a-gradio-app-over-to-streamlit" class="nav-link" data-scroll-target="#converting-a-gradio-app-over-to-streamlit">Converting a Gradio app over to Streamlit</a></li>
  <li><a href="#lessons-learned" id="toc-lessons-learned" class="nav-link" data-scroll-target="#lessons-learned">ü§î Lessons learned</a>
  <ul class="collapse">
  <li><a href="#when-to-use-gradio" id="toc-when-to-use-gradio" class="nav-link" data-scroll-target="#when-to-use-gradio">üìê When to use Gradio</a></li>
  <li><a href="#when-to-use-streamlit" id="toc-when-to-use-streamlit" class="nav-link" data-scroll-target="#when-to-use-streamlit">üåä When to use Streamlit</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="motivation" class="level1">
<h1>üö¶ Motivation</h1>
<p>After the second class of the fastai course, we‚Äôre encouraged to create mini-projects that result in models we can deploy online. Deployment is a huge field with its own complexities, of course, but having an option to get something out in the world that‚Äôs visible and usable is extremely useful.</p>
<p>In this post, I will walk you through how I built a super quick MVP of my redacted document detector project. I used:</p>
<ul>
<li><a href="https://github.com/fastai/fastai"><code>fastai</code></a> to classify and extract redacted pages extracted from PDFs</li>
<li><a href="https://airctic.com/"><code>icevision</code></a> (<a href="https://twitter.com/ai_fast_track"><span class="citation" data-cites="ai_fast_track">@ai_fast_track</span></a>) to detect the redacted areas</li>
<li><a href="https://huggingface.co/spaces">HuggingFace Spaces</a> (with <a href="https://gradio.app">Gradio</a> and <a href="https://streamlit.io">Streamlit</a>) to deploy my MVP</li>
</ul>
<p>The post shows how I went about thinking through the task, showcasing some examples of small prototypes I built along the way, including the final stage where I built: - an app including everything that would be needed by a final ‚Äòdeployed‚Äô use case of my model - two models working in tandem in the same app (one classification, one object detection) - optional PDF generation of items detected by the model (!)</p>
<p>I also explore why you might want to have a minimal deployed version of your application in the first place!</p>
</section>
<section id="step-by-step-iteration-by-iteration" class="level1">
<h1>üêæ Step by step, iteration by iteration</h1>
<p>This week I chose to use my previous work on redacted images to leverage a dataset <a href="https://mlops.systems/fastai/redactionmodel/computervision/datalabelling/2021/09/06/redaction-classification-chapter-2.html">I‚Äôd previously collected</a>. I wanted to showcase something useful and interesting and I ended up slightly blocked as to what I was going to build. After discussing it with <a href="https://www.meetup.com/delft-fast-ai-study-group/">the study group</a> briefly, I was reminded not to try to bite off too much: start small with the smallest possible next version of what you want, and then continue from there.</p>
<p>Since I already had a large dataset of redacted and unredacted images (extracted from PDF documents available online), I used this to train a classification model that could tell whether a page contained redactions or not.</p>
<p>With that model exported, it was then easy to get a simple <a href="https://gradio.app">Gradio</a> app demo up and running, particularly with the suggestions in Tanishq Abraham‚Äôs <a href="https://tmabraham.github.io/blog/gradio_hf_spaces_tutorial">really useful tutorial blogpost</a>.</p>
<p>It‚Äôs an easy step to go from having a Gradio app deployed to then hosting that same demo as a Huggingface Space, so I then did that. You can <a href="https://huggingface.co/spaces/strickvl/fastai_redaction_classifier">access the demo here</a> at <a href="https://huggingface.co/spaces/strickvl/fastai_redaction_classifier"><code>strickvl/fastai_redaction_classifier</code></a>.</p>
<p><img src="redaction-mvp-huggingface/classification-demo.png" title="A Gradio app hosted on Huggingface Spaces: an image classifier that detects whether an image input contains a redaction or not." class="img-fluid"></p>
<p>At this first stage I had the exported model itself uploaded inside the Spaces repository, but <a href="https://huggingface.co/blog/fastai">this useful blog</a> by Omar Espejel showed how I could just upload my model directly to the Huggingface model hub. Instead of calling <code>learn.export('model.pkl')</code> and uploading the model file itself, I could just run the following code after authentication:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> huggingface_hub <span class="im">import</span> push_to_hub_fastai</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>repo_id <span class="op">=</span> <span class="st">"MY_USERNAME/MY_LEARNER_NAME"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>push_to_hub_fastai(learner<span class="op">=</span>learn, repo_id<span class="op">=</span>repo_id)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>My model <a href="https://huggingface.co/strickvl/redaction-classifier-fastai">lives here</a> on the Huggingface model hub and can be directly saved or just used via the hosted Inference API.</p>
</section>
<section id="using-the-inference-api-for-more-flexibility" class="level1">
<h1>‚ö°Ô∏è Using the inference API for more flexibility</h1>
<p>Buoyed on by Tanishq‚Äôs blog and the workflow we‚Äôd seen in the lecture that week, I thought it might be worth running my inference requests through the HTTP API instead of letting Huggingface handle all that.</p>
<p>Thanks to a really simple and comprehensible <a href="https://github.com/nuvic/predict_image">example</a> made by <a href="https://github.com/nuvic"><span class="citation" data-cites="Nuvic">@Nuvic</span></a> I was quickly able to get something up and running. The forked source code is available <a href="https://github.com/strickvl/predict_redaction_classification">here</a> and the main website where you can try out the tool is here: <a href="https://strickvl.github.io/predict_redaction_classification/">https://strickvl.github.io/predict_redaction_classification/</a>.</p>
<p>If you <a href="https://duckduckgo.com/?q=redacted+document&amp;t=osx&amp;iax=images&amp;ia=images">search for ‚Äòredacted document‚Äô images</a> and save one of them do your local computer you can use those to try it out. It uses simple Javascript code to pass the image you upload into the inference API using a simple HTTP request. It parses the results and displays them as shown here:</p>
<p><img src="redaction-mvp-huggingface/gh-pages-demo.png" title="A demo using Github Pages to host a simple app showcasing the model inference." class="img-fluid"></p>
<p>While the demo gives a sense of the model‚Äôs capabilities, in reality you would probably not find it very helpful to use a web app that required you to feed a document‚Äôs pages to it one by one. I started to think about a more complex application where you could upload a PDF and it would split the PDF for you and do all the inference behind the scenes.</p>
</section>
<section id="building-an-mvp-of-a-redaction-detection-application" class="level1">
<h1>üöÄ Building an MVP of a redaction detection application</h1>
<p>I spent a brief half-hour considering deploying a simple <a href="https://flask.palletsprojects.com/en/2.1.x/">Flask</a> web app hosted somewhere for free before realising I didn‚Äôt even need to go that far to create a proof of concept that would have the required functionality. I returned back to Huggingface Spaces hoping that I‚Äôd be able to build everything out.</p>
<p>You can access the demo / MVP app that I created here: <a href="https://huggingface.co/spaces/strickvl/redaction-detector">https://huggingface.co/spaces/strickvl/redaction-detector</a></p>
<p><img src="redaction-mvp-huggingface/demo-screenshot.png" title="An MVP app for detection, extraction and analysis of PDF documents that contain redactions." class="img-fluid"></p>
<p>This MVP app runs two models to mimic the experience of what a final deployed version of the project might look like.</p>
<ul>
<li>The first model (a classification model trained with fastai, available on the Huggingface Hub <a href="https://huggingface.co/strickvl/redaction-classifier-fastai">here</a> and testable as a standalone demo <a href="https://huggingface.co/spaces/strickvl/fastai_redaction_classifier">here</a>), classifies and determines which pages of the PDF are redacted. I‚Äôve written about how I trained this model <a href="https://mlops.systems/fastai/redactionmodel/computervision/datalabelling/2021/09/06/redaction-classification-chapter-2.html">here</a>.</li>
<li>The second model (an object detection model trained using <a href="https://airctic.com/">IceVision</a> (itself built partly on top of fastai)) detects which parts of the image are redacted. This is a model I‚Äôve been working on for a while and I described my process in <a href="https://mlops.systems/#category=redactionmodel">a series of blog posts</a>.</li>
</ul>
<p>This MVP app does several things:</p>
<ul>
<li>it extracts any pages it considers to contain redactions and displays that subset as an <a href="https://gradio.app/docs/#o_carousel">image carousel</a>. It also displays some text alerting you to which specific pages were redacted.</li>
<li>if you click the ‚ÄúAnalyse and extract redacted images‚Äù checkbox, it will:</li>
<li>pass the pages it considered redacted through the object detection model</li>
<li>calculate what proportion of the total area of the image was redacted as well as what proportion of the actual content (i.e.&nbsp;excluding margins etc where there is no content)</li>
<li>create a PDF that you can download that contains only the redacted images, with an overlay of the redactions that it was able to identify along with the confidence score for each item.</li>
</ul>
</section>
<section id="converting-a-gradio-app-over-to-streamlit" class="level1">
<h1>Converting a Gradio app over to Streamlit</h1>
<p>I was curious about the differences between the main two options enabled by Huggingface Spaces, so I then worked a little on converting my Gradio app to a Streamlit app. The process of conversion was fairly easy for the most part; the only difference is the style of programming expected by Streamlit:</p>
<ul>
<li>Streamlit is a less declarative style of creating your app. It runs your code from top to bottom, rendering whatever elements you specify.</li>
<li>This seems to result in more verbose code (e.g.&nbsp;compare <a href="https://huggingface.co/spaces/strickvl/redaction-detector/blob/main/app.py">this</a> with <a href="https://huggingface.co/spaces/strickvl/redaction-detector-streamlit/blob/main/streamlit_app.py">this</a>).</li>
</ul>
<p>There are two easy ways to deploy a Streamlit app: either host it natively on Streamlit itself, or host it on Huggingface Spaces. The advantage of hosting natively on Streamlit is that you essentially have what looks and feels like a custom website that is 100% your application. In the end, I didn‚Äôt go down this route for two reasons:</p>
<ol type="1">
<li>Hosting via Huggingface Spaces keeps the connection between your demo app and your username. You can click through to view all of my demos and applications <a href="https://huggingface.co/strickvl">here</a>, for example. On Streamlit there is currently no concept of a user‚Äôs portfolio. If you‚Äôre trying to showcase your work, Huggingface Spaces is the clear winner in this regard.</li>
<li>Hosting on Streamlit seems to have restrictive memory constraints. I frequently ran into restrictions on the machine that was running my application and would quite often be encouraged to reboot my app, clearing its cache, and instructed to refer to <a href="https://blog.streamlit.io/common-app-problems-resource-limits/">docs on how to make my application more efficient</a>. The docs were useful, but I ran into issues using the Streamlit cache (the main solution offered) because of the models I was using. Luckily, Huggingface Spaces‚Äô backend instances seem far more generous in terms of resources. For small / trivial apps not doing much you‚Äôll be fine with Streamlit, but for anything more involved there‚Äôs more of a decision to be made.</li>
</ol>
<p>I didn‚Äôt convert all the various parts of my Gradio app over to work on Streamlit ‚Äî in particular extraction of images and display as a carousel was non-trivial ‚Äî but you can get a sense of the flexibility with this image:</p>
<p><img src="redaction-mvp-huggingface/demo-streamlit.png" title="A partly converted version of my demo app using Streamlit." class="img-fluid"></p>
<p>(Alternatively, you can try it out over on Huggingface Spaces <a href="https://huggingface.co/spaces/strickvl/redaction-detector-streamlit">here</a>.)</p>
<p>You can see that I was able to insert a chart to display the proportion calculations. This is much more pleasant than the pure text version. Streamlit‚Äôs <a href="https://docs.streamlit.io">documentation</a> is pretty great and their basic <a href="https://docs.streamlit.io/library/get-started">‚ÄòGet started‚Äô tutorial</a> should indeed be your first port of call.</p>
</section>
<section id="lessons-learned" class="level1">
<h1>ü§î Lessons learned</h1>
{% include info.html text=‚Äú
<p>
In this post you learned:
</p>
<p>
1Ô∏è‚É£ to start with simple prototypes
</p>
<p>
2Ô∏è‚É£ how to easily deploy fastai models on Huggingface Spaces and the Hub and
</p>
<p>
3Ô∏è‚É£ that you can create functional MVP demos of real products and applications
</p>
<p>‚Äù %}</p>
<p>I was ‚Äî and continue to be ‚Äî surprised that the free Huggingface Spaces environment has no problem running all this fairly compute-intensive inference on their backend. (That said, if you try to upload a document containing dozens or hundreds of pages and you‚Äôll quickly hit up against the edge of what they allow.)</p>
<p>I became very familiar with the <a href="https://gradio.app/docs/">Gradio interface docs</a> while creating this app and was impressed by how customisable the final application could be. You don‚Äôt have as much freedom as a web application written from scratch, but you still <em>do</em> have a lot of freedom.</p>
<section id="when-to-use-gradio" class="level2">
<h2 class="anchored" data-anchor-id="when-to-use-gradio">üìê When to use Gradio</h2>
<ul>
<li>if you have a simple use case that you want to highlight</li>
<li>if your inputs and outputs are clearly defined</li>
<li>if you have a single model to showcase</li>
<li>if you want to get something quickly deployed</li>
</ul>
</section>
<section id="when-to-use-streamlit" class="level2">
<h2 class="anchored" data-anchor-id="when-to-use-streamlit">üåä When to use Streamlit</h2>
<ul>
<li>if your use case is more interactive or less simple than just basic input-then-output</li>
<li>if you want more control on how your demo application is displayed</li>
<li>if you enjoy a more imperative style of programming</li>
</ul>
<p>Given how much inference is going on behind the scenes, I‚Äôm surprised that these applications run as fast as it does. For a document with 4 or 5 redacted pages, it takes around 10 seconds to do all the steps described above. 10 seconds is still far too long for a scenario where you wanted to run inference over millions of pages, but in that scenario you wouldn‚Äôt be manually uploading them on a web app either.</p>
<p>It‚Äôs extremely gratifying to have these kinds of tools available to use for free, and really exciting that you get to build out prototypes of this kind after just two weeks of study on the fastai course.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>