<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Alex Strick van Linschoten">
<meta name="dcterms.date" content="2022-05-07">
<meta name="description" content="I created a few deployed MVP demos showcasing models I’d created while participating in the fastai course, uploading them to the Huggingface Hub and using a Gradio Demo hosted on Huggingface Spaces.">

<title>Alex Strick van Linschoten - A painless way to create an MVP demo using computer vision models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script defer="" data-domain="mlops.systems" src="https://plausible.io/js/script.js"></script>


<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="Alex Strick van Linschoten - A painless way to create an MVP demo using computer vision models">
<meta property="og:description" content="I created a few deployed MVP demos showcasing models I'd created while participating in the fastai course, uploading them to the Huggingface Hub and using a Gradio Demo hosted on Huggingface Spaces.">
<meta property="og:image" content="https://mlops.systems/posts/redaction-mvp-huggingface/demo-screenshot.png">
<meta property="og:site-name" content="Alex Strick van Linschoten">
<meta property="og:image:height" content="565">
<meta property="og:image:width" content="700">
<meta name="twitter:title" content="Alex Strick van Linschoten - A painless way to create an MVP demo using computer vision models">
<meta name="twitter:description" content="I created a few deployed MVP demos showcasing models I'd created while participating in the fastai course, uploading them to the Huggingface Hub and using a Gradio Demo hosted on Huggingface Spaces.">
<meta name="twitter:image" content="https://mlops.systems/posts/redaction-mvp-huggingface/demo-screenshot.png">
<meta name="twitter:creator" content="@strickvl">
<meta name="twitter:image-height" content="565">
<meta name="twitter:image-width" content="700">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Alex Strick van Linschoten</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../til.html">
 <span class="menu-text">TIL</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/strickvl"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://sigmoid.social/web/@alexstrick"><i class="bi bi-mastodon" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/strickvl"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://mlops.systems/index.xml"><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">A painless way to create an MVP demo using computer vision models</h1>
                  <div>
        <div class="description">
          I created a few deployed MVP demos showcasing models I’d created while participating in the fastai course, uploading them to the Huggingface Hub and using a Gradio Demo hosted on Huggingface Spaces.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">fastai</div>
                <div class="quarto-category">computervision</div>
                <div class="quarto-category">redactionmodel</div>
                <div class="quarto-category">tools</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Alex Strick van Linschoten </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 7, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#motivation" id="toc-motivation" class="nav-link active" data-scroll-target="#motivation">🚦 Motivation</a></li>
  <li><a href="#step-by-step-iteration-by-iteration" id="toc-step-by-step-iteration-by-iteration" class="nav-link" data-scroll-target="#step-by-step-iteration-by-iteration">🐾 Step by step, iteration by iteration</a></li>
  <li><a href="#using-the-inference-api-for-more-flexibility" id="toc-using-the-inference-api-for-more-flexibility" class="nav-link" data-scroll-target="#using-the-inference-api-for-more-flexibility">⚡️ Using the inference API for more flexibility</a></li>
  <li><a href="#building-an-mvp-of-a-redaction-detection-application" id="toc-building-an-mvp-of-a-redaction-detection-application" class="nav-link" data-scroll-target="#building-an-mvp-of-a-redaction-detection-application">🚀 Building an MVP of a redaction detection application</a></li>
  <li><a href="#converting-a-gradio-app-over-to-streamlit" id="toc-converting-a-gradio-app-over-to-streamlit" class="nav-link" data-scroll-target="#converting-a-gradio-app-over-to-streamlit">Converting a Gradio app over to Streamlit</a></li>
  <li><a href="#lessons-learned" id="toc-lessons-learned" class="nav-link" data-scroll-target="#lessons-learned">🤔 Lessons learned</a>
  <ul class="collapse">
  <li><a href="#when-to-use-gradio" id="toc-when-to-use-gradio" class="nav-link" data-scroll-target="#when-to-use-gradio">📐 When to use Gradio</a></li>
  <li><a href="#when-to-use-streamlit" id="toc-when-to-use-streamlit" class="nav-link" data-scroll-target="#when-to-use-streamlit">🌊 When to use Streamlit</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="motivation" class="level1">
<h1>🚦 Motivation</h1>
<p>After the second class of the fastai course, we’re encouraged to create mini-projects that result in models we can deploy online. Deployment is a huge field with its own complexities, of course, but having an option to get something out in the world that’s visible and usable is extremely useful.</p>
<p>In this post, I will walk you through how I built a super quick MVP of my redacted document detector project. I used:</p>
<ul>
<li><a href="https://github.com/fastai/fastai"><code>fastai</code></a> to classify and extract redacted pages extracted from PDFs</li>
<li><a href="https://airctic.com/"><code>icevision</code></a> (<a href="https://twitter.com/ai_fast_track"><span class="citation" data-cites="ai_fast_track">@ai_fast_track</span></a>) to detect the redacted areas</li>
<li><a href="https://huggingface.co/spaces">HuggingFace Spaces</a> (with <a href="https://gradio.app">Gradio</a> and <a href="https://streamlit.io">Streamlit</a>) to deploy my MVP</li>
</ul>
<p>The post shows how I went about thinking through the task, showcasing some examples of small prototypes I built along the way, including the final stage where I built: - an app including everything that would be needed by a final ‘deployed’ use case of my model - two models working in tandem in the same app (one classification, one object detection) - optional PDF generation of items detected by the model (!)</p>
<p>I also explore why you might want to have a minimal deployed version of your application in the first place!</p>
</section>
<section id="step-by-step-iteration-by-iteration" class="level1">
<h1>🐾 Step by step, iteration by iteration</h1>
<p>This week I chose to use my previous work on redacted images to leverage a dataset <a href="https://mlops.systems/fastai/redactionmodel/computervision/datalabelling/2021/09/06/redaction-classification-chapter-2.html">I’d previously collected</a>. I wanted to showcase something useful and interesting and I ended up slightly blocked as to what I was going to build. After discussing it with <a href="https://www.meetup.com/delft-fast-ai-study-group/">the study group</a> briefly, I was reminded not to try to bite off too much: start small with the smallest possible next version of what you want, and then continue from there.</p>
<p>Since I already had a large dataset of redacted and unredacted images (extracted from PDF documents available online), I used this to train a classification model that could tell whether a page contained redactions or not.</p>
<p>With that model exported, it was then easy to get a simple <a href="https://gradio.app">Gradio</a> app demo up and running, particularly with the suggestions in Tanishq Abraham’s <a href="https://tmabraham.github.io/blog/gradio_hf_spaces_tutorial">really useful tutorial blogpost</a>.</p>
<p>It’s an easy step to go from having a Gradio app deployed to then hosting that same demo as a Huggingface Space, so I then did that. You can <a href="https://huggingface.co/spaces/strickvl/fastai_redaction_classifier">access the demo here</a> at <a href="https://huggingface.co/spaces/strickvl/fastai_redaction_classifier"><code>strickvl/fastai_redaction_classifier</code></a>.</p>
<p><img src="redaction-mvp-huggingface/classification-demo.png" title="A Gradio app hosted on Huggingface Spaces: an image classifier that detects whether an image input contains a redaction or not." class="img-fluid"></p>
<p>At this first stage I had the exported model itself uploaded inside the Spaces repository, but <a href="https://huggingface.co/blog/fastai">this useful blog</a> by Omar Espejel showed how I could just upload my model directly to the Huggingface model hub. Instead of calling <code>learn.export('model.pkl')</code> and uploading the model file itself, I could just run the following code after authentication:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> huggingface_hub <span class="im">import</span> push_to_hub_fastai</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>repo_id <span class="op">=</span> <span class="st">"MY_USERNAME/MY_LEARNER_NAME"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>push_to_hub_fastai(learner<span class="op">=</span>learn, repo_id<span class="op">=</span>repo_id)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>My model <a href="https://huggingface.co/strickvl/redaction-classifier-fastai">lives here</a> on the Huggingface model hub and can be directly saved or just used via the hosted Inference API.</p>
</section>
<section id="using-the-inference-api-for-more-flexibility" class="level1">
<h1>⚡️ Using the inference API for more flexibility</h1>
<p>Buoyed on by Tanishq’s blog and the workflow we’d seen in the lecture that week, I thought it might be worth running my inference requests through the HTTP API instead of letting Huggingface handle all that.</p>
<p>Thanks to a really simple and comprehensible <a href="https://github.com/nuvic/predict_image">example</a> made by <a href="https://github.com/nuvic"><span class="citation" data-cites="Nuvic">@Nuvic</span></a> I was quickly able to get something up and running. The forked source code is available <a href="https://github.com/strickvl/predict_redaction_classification">here</a> and the main website where you can try out the tool is here: <a href="https://strickvl.github.io/predict_redaction_classification/">https://strickvl.github.io/predict_redaction_classification/</a>.</p>
<p>If you <a href="https://duckduckgo.com/?q=redacted+document&amp;t=osx&amp;iax=images&amp;ia=images">search for ‘redacted document’ images</a> and save one of them do your local computer you can use those to try it out. It uses simple Javascript code to pass the image you upload into the inference API using a simple HTTP request. It parses the results and displays them as shown here:</p>
<p><img src="redaction-mvp-huggingface/gh-pages-demo.png" title="A demo using Github Pages to host a simple app showcasing the model inference." class="img-fluid"></p>
<p>While the demo gives a sense of the model’s capabilities, in reality you would probably not find it very helpful to use a web app that required you to feed a document’s pages to it one by one. I started to think about a more complex application where you could upload a PDF and it would split the PDF for you and do all the inference behind the scenes.</p>
</section>
<section id="building-an-mvp-of-a-redaction-detection-application" class="level1">
<h1>🚀 Building an MVP of a redaction detection application</h1>
<p>I spent a brief half-hour considering deploying a simple <a href="https://flask.palletsprojects.com/en/2.1.x/">Flask</a> web app hosted somewhere for free before realising I didn’t even need to go that far to create a proof of concept that would have the required functionality. I returned back to Huggingface Spaces hoping that I’d be able to build everything out.</p>
<p>You can access the demo / MVP app that I created here: <a href="https://huggingface.co/spaces/strickvl/redaction-detector">https://huggingface.co/spaces/strickvl/redaction-detector</a></p>
<p><img src="redaction-mvp-huggingface/demo-screenshot.png" title="An MVP app for detection, extraction and analysis of PDF documents that contain redactions." class="img-fluid"></p>
<p>This MVP app runs two models to mimic the experience of what a final deployed version of the project might look like.</p>
<ul>
<li>The first model (a classification model trained with fastai, available on the Huggingface Hub <a href="https://huggingface.co/strickvl/redaction-classifier-fastai">here</a> and testable as a standalone demo <a href="https://huggingface.co/spaces/strickvl/fastai_redaction_classifier">here</a>), classifies and determines which pages of the PDF are redacted. I’ve written about how I trained this model <a href="https://mlops.systems/fastai/redactionmodel/computervision/datalabelling/2021/09/06/redaction-classification-chapter-2.html">here</a>.</li>
<li>The second model (an object detection model trained using <a href="https://airctic.com/">IceVision</a> (itself built partly on top of fastai)) detects which parts of the image are redacted. This is a model I’ve been working on for a while and I described my process in <a href="https://mlops.systems/#category=redactionmodel">a series of blog posts</a>.</li>
</ul>
<p>This MVP app does several things:</p>
<ul>
<li>it extracts any pages it considers to contain redactions and displays that subset as an <a href="https://gradio.app/docs/#o_carousel">image carousel</a>. It also displays some text alerting you to which specific pages were redacted.</li>
<li>if you click the “Analyse and extract redacted images” checkbox, it will:</li>
<li>pass the pages it considered redacted through the object detection model</li>
<li>calculate what proportion of the total area of the image was redacted as well as what proportion of the actual content (i.e.&nbsp;excluding margins etc where there is no content)</li>
<li>create a PDF that you can download that contains only the redacted images, with an overlay of the redactions that it was able to identify along with the confidence score for each item.</li>
</ul>
</section>
<section id="converting-a-gradio-app-over-to-streamlit" class="level1">
<h1>Converting a Gradio app over to Streamlit</h1>
<p>I was curious about the differences between the main two options enabled by Huggingface Spaces, so I then worked a little on converting my Gradio app to a Streamlit app. The process of conversion was fairly easy for the most part; the only difference is the style of programming expected by Streamlit:</p>
<ul>
<li>Streamlit is a less declarative style of creating your app. It runs your code from top to bottom, rendering whatever elements you specify.</li>
<li>This seems to result in more verbose code (e.g.&nbsp;compare <a href="https://huggingface.co/spaces/strickvl/redaction-detector/blob/main/app.py">this</a> with <a href="https://huggingface.co/spaces/strickvl/redaction-detector-streamlit/blob/main/streamlit_app.py">this</a>).</li>
</ul>
<p>There are two easy ways to deploy a Streamlit app: either host it natively on Streamlit itself, or host it on Huggingface Spaces. The advantage of hosting natively on Streamlit is that you essentially have what looks and feels like a custom website that is 100% your application. In the end, I didn’t go down this route for two reasons:</p>
<ol type="1">
<li>Hosting via Huggingface Spaces keeps the connection between your demo app and your username. You can click through to view all of my demos and applications <a href="https://huggingface.co/strickvl">here</a>, for example. On Streamlit there is currently no concept of a user’s portfolio. If you’re trying to showcase your work, Huggingface Spaces is the clear winner in this regard.</li>
<li>Hosting on Streamlit seems to have restrictive memory constraints. I frequently ran into restrictions on the machine that was running my application and would quite often be encouraged to reboot my app, clearing its cache, and instructed to refer to <a href="https://blog.streamlit.io/common-app-problems-resource-limits/">docs on how to make my application more efficient</a>. The docs were useful, but I ran into issues using the Streamlit cache (the main solution offered) because of the models I was using. Luckily, Huggingface Spaces’ backend instances seem far more generous in terms of resources. For small / trivial apps not doing much you’ll be fine with Streamlit, but for anything more involved there’s more of a decision to be made.</li>
</ol>
<p>I didn’t convert all the various parts of my Gradio app over to work on Streamlit — in particular extraction of images and display as a carousel was non-trivial — but you can get a sense of the flexibility with this image:</p>
<p><img src="redaction-mvp-huggingface/demo-streamlit.png" title="A partly converted version of my demo app using Streamlit." class="img-fluid"></p>
<p>(Alternatively, you can try it out over on Huggingface Spaces <a href="https://huggingface.co/spaces/strickvl/redaction-detector-streamlit">here</a>.)</p>
<p>You can see that I was able to insert a chart to display the proportion calculations. This is much more pleasant than the pure text version. Streamlit’s <a href="https://docs.streamlit.io">documentation</a> is pretty great and their basic <a href="https://docs.streamlit.io/library/get-started">‘Get started’ tutorial</a> should indeed be your first port of call.</p>
</section>
<section id="lessons-learned" class="level1">
<h1>🤔 Lessons learned</h1>
{% include info.html text=“
<p>
In this post you learned:
</p>
<p>
1️⃣ to start with simple prototypes
</p>
<p>
2️⃣ how to easily deploy fastai models on Huggingface Spaces and the Hub and
</p>
<p>
3️⃣ that you can create functional MVP demos of real products and applications
</p>
<p>” %}</p>
<p>I was — and continue to be — surprised that the free Huggingface Spaces environment has no problem running all this fairly compute-intensive inference on their backend. (That said, if you try to upload a document containing dozens or hundreds of pages and you’ll quickly hit up against the edge of what they allow.)</p>
<p>I became very familiar with the <a href="https://gradio.app/docs/">Gradio interface docs</a> while creating this app and was impressed by how customisable the final application could be. You don’t have as much freedom as a web application written from scratch, but you still <em>do</em> have a lot of freedom.</p>
<section id="when-to-use-gradio" class="level2">
<h2 class="anchored" data-anchor-id="when-to-use-gradio">📐 When to use Gradio</h2>
<ul>
<li>if you have a simple use case that you want to highlight</li>
<li>if your inputs and outputs are clearly defined</li>
<li>if you have a single model to showcase</li>
<li>if you want to get something quickly deployed</li>
</ul>
</section>
<section id="when-to-use-streamlit" class="level2">
<h2 class="anchored" data-anchor-id="when-to-use-streamlit">🌊 When to use Streamlit</h2>
<ul>
<li>if your use case is more interactive or less simple than just basic input-then-output</li>
<li>if you want more control on how your demo application is displayed</li>
<li>if you enjoy a more imperative style of programming</li>
</ul>
<p>Given how much inference is going on behind the scenes, I’m surprised that these applications run as fast as it does. For a document with 4 or 5 redacted pages, it takes around 10 seconds to do all the steps described above. 10 seconds is still far too long for a scenario where you wanted to run inference over millions of pages, but in that scenario you wouldn’t be manually uploading them on a web app either.</p>
<p>It’s extremely gratifying to have these kinds of tools available to use for free, and really exciting that you get to build out prototypes of this kind after just two weeks of study on the fastai course.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>