{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "aliases:\n",
    "- /fastai/computervision/pytorch/2022/05/14/SGD-fashion-mnist.html\n",
    "date: '2022-05-14'\n",
    "description: I apply all the lessons we've learned so far on the Fashion MNIST dataset.\n",
    "  This requires us learning a few new concepts like optimisers, ReLU, nonlinearity\n",
    "  and so on.\n",
    "output-file: 2022-05-14-sgd-fashion-mnist.html\n",
    "title: Using the seven-step SGD process for Fashion MNIST\n",
    "image: fashion-mnist/fashion-mnist-small.png\n",
    "categories:\n",
    "- fastai\n",
    "- computervision\n",
    "- partone\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9976ac80-48c6-473e-8096-01759c7321ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "!pip install -Uqq fastbook nbdev torch\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36397a43",
   "metadata": {},
   "source": [
    "In [the previous\n",
    "post](https://mlops.systems/fastai/computervision/pytorch/2022/05/13/sgd-whole-game.html)\n",
    "I used the seven-step process to fit to an unknown function. The process as a\n",
    "whole is fairly simple to get your head around, but there are a good few details\n",
    "to keep track of along the way. This will continue to be the case as we get into\n",
    "this walkthrough of how to do the same for the Fashion MNIST pullover vs dress data.\n",
    "\n",
    "# Getting our data into the right format\n",
    "\n",
    "The first thing we need to handle is making sure our data is in the right\n",
    "format, shape and so on. We begin by downloading our data and splitting the data\n",
    "into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5e2581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6000, 28, 28]), torch.Size([1000, 28, 28]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "training_dresses = [item[0][0] for item in training_data if item[1] == 3]\n",
    "training_pullovers = [item[0][0] for item in training_data if item[1] == 2]\n",
    "test_dresses = [item[0][0] for item in test_data if item[1] == 3]\n",
    "test_pullovers = [item[0][0] for item in test_data if item[1] == 2]\n",
    "\n",
    "training_dresses_tensor = torch.stack(training_dresses)\n",
    "training_pullovers_tensor = torch.stack(training_pullovers)\n",
    "test_dresses_tensor = torch.stack(test_dresses)\n",
    "test_pullovers_tensor = torch.stack(test_pullovers)\n",
    "\n",
    "training_dresses_tensor.shape, test_dresses_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52db930f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12000, 784]), torch.Size([12000, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([training_dresses_tensor, training_pullovers_tensor]).view(-1, 28*28)\n",
    "train_y = torch.cat([torch.ones(len(training_dresses)), torch.zeros(len(training_pullovers))]).unsqueeze(1)\n",
    "\n",
    "valid_x = torch.cat([test_dresses_tensor, test_pullovers_tensor]).view(-1, 28*28)\n",
    "valid_y = torch.cat([torch.ones(len(test_dresses)), torch.zeros(len(test_pullovers))]).unsqueeze(1)\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f0ca4",
   "metadata": {},
   "source": [
    "We transform our images tensors from matrices into vectors with all the values\n",
    "one after another. We create a `train_y` vector with our labels which we can use\n",
    "to check how well we did with our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbacf5d",
   "metadata": {},
   "source": [
    "We create datasets out of our tensors. This means that we can feed our data into\n",
    "our training functions in the way that is most convenient (i.e. an image is\n",
    "paired with the correct label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4f4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = list(zip(train_x, train_y))\n",
    "valid_dset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f8c6ae",
   "metadata": {},
   "source": [
    "# Initialising our weights and bias\n",
    "\n",
    "As in the previous times where we've done this, we initialise our parameters or\n",
    "weights with random values. This means that for every pixel represented in the\n",
    "images, we'll start off with purely random values. We initialise our bias to a\n",
    "random number as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98066657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_params(size, std=1.0):\n",
    "    return (torch.randn(size) * std).requires_grad_()\n",
    "\n",
    "weights = initialise_params((28*28, 1))\n",
    "bias = initialise_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2307b400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8681], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating a prediction for our first image\n",
    "(train_x[0]*weights.T).sum() + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b8e1be",
   "metadata": {},
   "source": [
    "# Matrix multiplication to calculate our predictions\n",
    "\n",
    "We'll need to make many calculations like the one we just made, and luckily the\n",
    "technique of matrix multiplication helps us with exactly the scenario we have:\n",
    "we want to multiply the values of our image (laid out in a single vector) with\n",
    "the weights and to add the bias.\n",
    "\n",
    "In Python, matrix multiplication is carried out with a simple `@` operator, so\n",
    "we can bring all of this together as a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aca092bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.8681],\n",
       "        [ -7.6810],\n",
       "        [-17.5719],\n",
       "        ...,\n",
       "        [ -3.8665],\n",
       "        [  2.0646],\n",
       "        [ -2.5148]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear1(x_batch):\n",
    "    return x_batch@weights + bias\n",
    "\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38cb1d",
   "metadata": {},
   "source": [
    "We can check our accuracy for these predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f135590a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35324999690055847"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = (preds > 0.0).float() == train_y\n",
    "corrects.float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98d21f",
   "metadata": {},
   "source": [
    "Our accuracy is pretty poor! A lot worse than even 50/50 luck which is what\n",
    "you'd expect to get on average from a random set of initial weights. Apparently\n",
    "we had a bad draw of luck this time round!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008f187",
   "metadata": {},
   "source": [
    "# A loss function to evaluate model performance\n",
    "\n",
    "We now need a loss function which will tell us how well we are doing in our\n",
    "predictions, and that can be used as part of the gradient calculations to let us\n",
    "know (as we iterate) how to update our weights.\n",
    "\n",
    "The problem, especially in the data set we're working with, is that we have a\n",
    "binary probability: either it's a dress or a pullover. Zero or one. Unlike in a\n",
    "regression problem, or something similar, we don't have any smooth selection of\n",
    "contiguous values that get predicted. We have zero or one.\n",
    "\n",
    "At this point we learn about the sigmoid function which is a way to reframe this\n",
    "problem in a way that we can use to our advantage. The sigmoid function when\n",
    "plotted looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1489ac52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "plot_function(torch.sigmoid, title=\"Sigmoid\", min=-5, max=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8820be0b",
   "metadata": {},
   "source": [
    "This function, as you can see, takes any input value and squashes it down such\n",
    "that the output value is between 0 and 1. It also has a smooth curve, all headed\n",
    "in the same direction, between those values. This is ideal for our situation.\n",
    "The first thing we must do as part of our loss function, therefore, is to apply\n",
    "the sigmoid function to the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb974f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fashion_mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1 - predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94ebb9d",
   "metadata": {},
   "source": [
    "This `torch.where(...)` function is a handy way of iterating through all our\n",
    "data, checking whether our target is 1 or not, then outputting the distance from\n",
    "the correct prediction and calculating the mean of these predictions across the\n",
    "entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e9505",
   "metadata": {},
   "source": [
    "# DataLoaders and Datasets\n",
    "\n",
    "We've already created datasets for our training and validation data. The process\n",
    "of iterating through our data, however, requires some thought as to how we'll do\n",
    "it. Our options:\n",
    "\n",
    "- we could iterate through the entire dataset, making the relevant loss and\n",
    "  gradient calculations and adjusting the weights but this might make the\n",
    "  process quite long, even though we'd benefit from the increased accuracy this\n",
    "  would bring since we'd be seeing the entire dataset each iteration.\n",
    "- we could do our calculations after just seeing a single image, but then our\n",
    "  model would be over-influenced and perturbed by the fluctuations from image to\n",
    "  image. This also wouldn't be what we want.\n",
    "\n",
    "In practice, we'll need to choose something in between. This is where\n",
    "mini-batches or just 'batches' come in. These will be need to be large enough\n",
    "(and randomly populated!) that our model can meaningfully learn from them, but\n",
    "not so large that our process takes too long.\n",
    "\n",
    "Luckily, we have the abstraction of the `DataLoader` which will create all our\n",
    "randomly assigned batches for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4690ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dset, batch_size=256, shuffle=True)\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d34e13d",
   "metadata": {},
   "source": [
    "# Training our model\n",
    "\n",
    "Now we can bring the whole process together and train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb4b08c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2173"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = initialise_params((28*28, 1))\n",
    "bias = initialise_params(1)\n",
    "\n",
    "def calculate_gradient(x_batch, y_batch, model):\n",
    "    preds = model(x_batch)\n",
    "    loss = fashion_mnist_loss(preds, y_batch)\n",
    "    loss.backward()\n",
    "\n",
    "def train_epoch(model, learning_rate, params):\n",
    "    # iterate over the training data, batch by batch\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        # calculate the gradients\n",
    "        calculate_gradient(x_batch, y_batch, model)\n",
    "        \n",
    "        for param in params:\n",
    "            param.data -= param.grad * learning_rate\n",
    "            # set the gradients to zero\n",
    "            param.grad.zero_()\n",
    "\n",
    "def batch_accuracy(x_batch, y_batch):\n",
    "    preds = x_batch.sigmoid()\n",
    "    correct = (preds > 0.5) == y_batch\n",
    "    return correct.float().mean()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(x_batch), y_batch) for x_batch, y_batch in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc39252",
   "metadata": {},
   "source": [
    "We start there, but now we can train and watch our accuracy improving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c0f41f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5001 0.5016 0.7994 0.9357 0.9481 0.9523 0.9537 0.9555 0.9572 0.9582 0.9578 0.9604 0.9608 0.9609 0.962 0.9611 0.9622 0.9626 0.9631 0.9625 0.963 0.963 0.9633 0.9638 0.964 0.9631 0.9638 0.9638 0.9643 0.9645 "
     ]
    }
   ],
   "source": [
    "learning_rate = 1.\n",
    "params = weights, bias\n",
    "\n",
    "for _ in range(30):\n",
    "    train_epoch(linear1, learning_rate, params)\n",
    "    print(validate_epoch(linear1), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f2823",
   "metadata": {},
   "source": [
    "We had 91% accuracy on our validation dataset [last time we tried\n",
    "this](https://mlops.systems/fastai/computervision/pytorch/2022/05/11/fashion-mnist-pixel-similarity.html#Using-broadcasting-to-check-our-predictions-on-our-validation-data)\n",
    "with pixel similarity.\n",
    "\n",
    "After 30 epochs of training with our new process we've achieved 96%, but we\n",
    "could still do better! We'll tackle that in the next post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1202f8",
   "metadata": {},
   "source": [
    "\n",
    "# Optimising with an Optimiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293408e2",
   "metadata": {},
   "source": [
    "Everything that we've been doing so far is so common that there is pre-built\n",
    "functionality to handle all of the pieces.\n",
    "\n",
    "- our `linear1` function (which calculated predictions based on our weights and\n",
    "  biases) can be replaced with PyTorch's `nn.Linear` module. Actually,\n",
    "  `nn.Linear` does the same thing as our `initialise_params` and our `linear1`\n",
    "  function combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2624e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialises our weights and bias, and is our model / function\n",
    "linear_model = nn.Linear(28*28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b68aadf",
   "metadata": {},
   "source": [
    "Our PyTorch module carries an internal representation of our weights and our biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e2a846a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, bias = linear_model.parameters()\n",
    "weights.shape, bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6baa5",
   "metadata": {},
   "source": [
    "- an optimiser bundles the step functionality and the `zero_grad_`\n",
    "  functionality. In the book we see how to create our own very basic optimiser,\n",
    "  but `fastai` provides the basic `SGD` class which we can use that handles\n",
    "  these same behaviours.\n",
    "\n",
    "We'll need to amend our training function a little to take this into account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8104beb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96 0.9642 0.966 0.9659 0.9663 0.9672 0.9677 0.9668 0.9678 0.9684 0.9681 0.9674 0.9681 0.9671 0.9678 0.9677 0.9684 0.968 0.9687 0.9677 0.9681 0.968 0.9693 0.9684 0.968 0.9686 0.9688 0.9693 0.9698 0.9697 "
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28, 1)\n",
    "opt = SGD(linear_model.parameters(), learning_rate)\n",
    "\n",
    "def train_epoch(model):\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        calculate_gradient(x_batch, y_batch, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "def train_model(model, epochs):\n",
    "    for _ in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=\" \")\n",
    "\n",
    "train_model(linear_model, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7609a0d5",
   "metadata": {},
   "source": [
    "# Some extra `fastai` abstractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8243a15c",
   "metadata": {},
   "source": [
    "`fastai` handles so much of this for us all, such that the `Learner` is actually\n",
    "the thing we can use to get all of the above logic built in.\n",
    "\n",
    "The `Learner` takes all of the pieces that we've spent the last few blogs\n",
    "creating:\n",
    "\n",
    "- the `DataLoaders` (iterators providing the data in batches, in the right\n",
    "  format with paired `x` and `y` values)\n",
    "- the model itself (our function that we're trying to optimise)\n",
    "- the optimisation function (which receives our weights and bias parameters as\n",
    "  well as the learning rate)\n",
    "- the loss function\n",
    "- any optional metrics we want printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c0d1f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.063289</td>\n",
       "      <td>0.045487</td>\n",
       "      <td>0.963500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.044268</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>0.964500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.037112</td>\n",
       "      <td>0.040228</td>\n",
       "      <td>0.965500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.034010</td>\n",
       "      <td>0.038743</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.032013</td>\n",
       "      <td>0.038781</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.030633</td>\n",
       "      <td>0.037635</td>\n",
       "      <td>0.966500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030458</td>\n",
       "      <td>0.037530</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.029747</td>\n",
       "      <td>0.036593</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.029511</td>\n",
       "      <td>0.036479</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.029305</td>\n",
       "      <td>0.035645</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.028643</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.966500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.028562</td>\n",
       "      <td>0.035477</td>\n",
       "      <td>0.966500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.028788</td>\n",
       "      <td>0.035191</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.028261</td>\n",
       "      <td>0.034843</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.028172</td>\n",
       "      <td>0.034883</td>\n",
       "      <td>0.968500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "learn = Learner(dls, nn.Linear(28*28, 1), opt_func=SGD, loss_func=fashion_mnist_loss, metrics=batch_accuracy)\n",
    "\n",
    "learn.fit(15, lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8104da",
   "metadata": {},
   "source": [
    "So there we have it. We learned how to create a linear learner. Obviously 96.8%\n",
    "accuracy is pretty good, but it could be better. Next time we're going to add\n",
    "the final touches to this process by creating a neural network, adding layers of\n",
    "nonlinearity to ensure our function can fit the complex patterns in our data."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e0a4c679d9f6b5b7f0e3346667179a21ad75e9d85922afed17d29bd73315778"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('fastai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
