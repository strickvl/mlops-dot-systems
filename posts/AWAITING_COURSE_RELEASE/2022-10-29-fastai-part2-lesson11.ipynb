{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a809fef7-b3ec-4001-9d32-ccbdebb27588",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Matrix multiplication and broadcasting from the foundations\"\n",
    "author: \"Alex Strick van Linschoten\"\n",
    "date: \"2022-10-29\"\n",
    "categories: [computervision, fastai, parttwo]\n",
    "image: \"./images/part2-lesson11/matmul-cover.png\"\n",
    "toc: true\n",
    "draft: true\n",
    "description: \"Notes and some personal exploration following through the lesson\n",
    "11 course materials from FastAI part 2. We covered various ways to multiply\n",
    "matrices in Python, in increasing order of performance.\"\n",
    "comments:\n",
    "    utterances:\n",
    "        repo: strickvl/mlops-dot-systems\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13102e0c-9b4f-4aa3-ad6a-68bd8b4c31c1",
   "metadata": {},
   "source": [
    "(*This is part of a series of blog posts relating to and responding to the live\n",
    "FastAI course (part 2) being taught in late 2022. To read others, see the ones\n",
    "listed for [the ‘parttwo’ tag](https://mlops.systems/#category=parttwo).*)\n",
    "\n",
    "This week in the second half of the class we covered matrix multiplication and\n",
    "broadcasting. (I'll write a separate blog about the parts of lessons 9-11 where\n",
    "we discuss specific papers.) These two concepts are important because machine\n",
    "learning (and deep learning especially) is all about operations on matrices and\n",
    "vectors, so we both had best understand the concepts but also be able to\n",
    "make those calculations quickly and efficiently.\n",
    "\n",
    "At the bottom of this post, I'll also include my collation of the \"Things Jeremy\n",
    "says to do\" from this lesson. The relevant topics and libraries covered in this\n",
    "lecture are linked below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041b6ead-93f8-4256-84d0-f0c0fcf32ee5",
   "metadata": {},
   "source": [
    "| MetaTask          | Subtask                               | Concept / Skill       | Docs / Link                                                                                                                                                                    |\n",
    "| ----------------- | ------------------------------------- | --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| Multiply matrices | Implement basic matrix multiplication | Matrix multiplication | [link](https://youtu.be/kT4Mp9EdVqs)                                                                                                                                           |\n",
    "|                   | Pre-compile using numba               | Numba conversion      | [link](https://numba.pydata.org)                                                                                                                                               |\n",
    "|                   | Use elementwise ops                   | APL                   | [link](https://tryapl.org)                                                                                                                                                     |\n",
    "|                   |                                       | Frobenius norm        |                                                                                                                                                                                |\n",
    "|                   | Broadcast to match up matrices        | Broadcasting          | [link](https://numpy.org/doc/stable/user/basics.broadcasting.html) / [link](https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics)                    |\n",
    "|                   |                                       | `expand_as`           | [link](https://pytorch.org/docs/stable/generated/torch.Tensor.expand_as.html) / [link](https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html#torch.Tensor.expand) |\n",
    "|                   |                                       | `storage`             | [link](https://pytorch.org/docs/stable/generated/torch.Tensor.storage.html)                                                                                                    |\n",
    "|                   |                                       | stride                | [link](https://pytorch.org/docs/stable/generated/torch.Tensor.stride.html)                                                                                                     |\n",
    "|                   | Adding dimensions                     | `unsqueeze`           | [link](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html)                                                                                                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a06a16a",
   "metadata": {},
   "source": [
    "Before we get into the things we're doing with matrix multiplication, I'm\n",
    "including the code from [the previous post](https://mlops.systems/computervision/fastai/parttwo/2022/10/24/foundations-mnist-basics.html) so that the variables are available to\n",
    "us in this notebook, but hiding the cell so that it doesn't distract from the\n",
    "main content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82cd81a-d1bb-4948-8780-89444e1f38ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import tensor\n",
    "import gzip\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "import os\n",
    "import functools\n",
    "import operator\n",
    "import struct\n",
    "import array\n",
    "import tempfile\n",
    "\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "\n",
    "BASE_URL = \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/\"\n",
    "\n",
    "TRAINING_IMAGES = f\"{BASE_URL}train-images-idx3-ubyte.gz\"\n",
    "TRAINING_IMAGES_LABELS = f\"{BASE_URL}train-labels-idx1-ubyte.gz\"\n",
    "TEST_IMAGES = f\"{BASE_URL}t10k-images-idx3-ubyte.gz\"\n",
    "TEST_IMAGES_LABELS = f\"{BASE_URL}t10k-labels-idx1-ubyte.gz\"\n",
    "\n",
    "# create local path directory if it doesn't exist\n",
    "LOCAL_PATH = Path(\"data\")\n",
    "# check whether the path exists; create it if it doesn't exist\n",
    "if not LOCAL_PATH.exists():\n",
    "    LOCAL_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "training_images_path = LOCAL_PATH / \"train-images-idx3-ubyte.gz\"\n",
    "training_images_labels_path = LOCAL_PATH / \"train-labels-idx1-ubyte.gz\"\n",
    "test_images_path = LOCAL_PATH / \"t10k-images-idx3-ubyte.gz\"\n",
    "test_images_labels_path = LOCAL_PATH / \"t10k-labels-idx1-ubyte.gz\"\n",
    "\n",
    "# download the raw data if it doesn't exist\n",
    "if not training_images_path.exists():\n",
    "    urlretrieve(TRAINING_IMAGES, training_images_path)\n",
    "if not training_images_labels_path.exists():\n",
    "    urlretrieve(TRAINING_IMAGES_LABELS, training_images_labels_path)\n",
    "if not test_images_path.exists():\n",
    "    urlretrieve(TEST_IMAGES, test_images_path)\n",
    "if not test_images_labels_path.exists():\n",
    "    urlretrieve(TEST_IMAGES_LABELS, test_images_labels_path)\n",
    "\n",
    "# taken from https://github.com/datapythonista/mnist/blob/master/mnist/__init__.py\n",
    "\n",
    "def parse_idx(fd):\n",
    "    \"\"\"Parse an IDX file, and return it as an array of arrays.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fd : file\n",
    "        File descriptor of the IDX file to parse\n",
    "    endian : str\n",
    "        Byte order of the IDX file. See [1] for available options\n",
    "    Returns\n",
    "    -------\n",
    "    data : array\n",
    "        Numpy array with the dimensions and the data in the IDX file\n",
    "    1. https://docs.python.org/3/library/struct.html\n",
    "        #byte-order-size-and-alignment\n",
    "    \"\"\"\n",
    "    DATA_TYPES = {\n",
    "        0x08: \"B\",  # unsigned byte\n",
    "        0x09: \"b\",  # signed byte\n",
    "        0x0B: \"h\",  # short (2 bytes)\n",
    "        0x0C: \"i\",  # int (4 bytes)\n",
    "        0x0D: \"f\",  # float (4 bytes)\n",
    "        0x0E: \"d\",\n",
    "    }  # double (8 bytes)\n",
    "\n",
    "    header = fd.read(4)\n",
    "    if len(header) != 4:\n",
    "        raise IdxDecodeError(\n",
    "            \"Invalid IDX file, \"\n",
    "            \"file empty or does not contain a full header.\"\n",
    "        )\n",
    "\n",
    "    zeros, data_type, num_dimensions = struct.unpack(\">HBB\", header)\n",
    "\n",
    "    if zeros != 0:\n",
    "        raise IdxDecodeError(\n",
    "            \"Invalid IDX file, \"\n",
    "            \"file must start with two zero bytes. \"\n",
    "            \"Found 0x%02x\" % zeros\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        data_type = DATA_TYPES[data_type]\n",
    "    except KeyError:\n",
    "        raise IdxDecodeError(\n",
    "            \"Unknown data type \" \"0x%02x in IDX file\" % data_type\n",
    "        )\n",
    "\n",
    "    dimension_sizes = struct.unpack(\n",
    "        \">\" + \"I\" * num_dimensions, fd.read(4 * num_dimensions)\n",
    "    )\n",
    "\n",
    "    data = array.array(data_type, fd.read())\n",
    "    data.byteswap()  # looks like array.array reads data as little endian\n",
    "\n",
    "    expected_items = functools.reduce(operator.mul, dimension_sizes)\n",
    "    if len(data) != expected_items:\n",
    "        raise IdxDecodeError(\n",
    "            \"IDX file has wrong number of items. \"\n",
    "            \"Expected: %d. Found: %d\" % (expected_items, len(data))\n",
    "        )\n",
    "    return data\n",
    "\n",
    "# chunk things together\n",
    "def chunks(x, size):\n",
    "    for i in range(0, len(x), size):\n",
    "        yield x[i : i + size]\n",
    "\n",
    "# unzip the files and extract the images\n",
    "with gzip.open(training_images_path, \"rb\") as f:\n",
    "    pixels = list(parse_idx(f))\n",
    "    x_train = list(chunks(pixels, 784))\n",
    "\n",
    "with gzip.open(training_images_labels_path, \"rb\") as f:\n",
    "    y_train = list(parse_idx(f))\n",
    "\n",
    "with gzip.open(test_images_path, \"rb\") as f:\n",
    "    pixels = list(parse_idx(f))\n",
    "    x_valid = list(chunks(pixels, 784))\n",
    "\n",
    "with gzip.open(test_images_labels_path, \"rb\") as f:\n",
    "    y_valid = list(parse_idx(f))\n",
    "\n",
    "# this list is taken from the README of the Fashion-MNIST repository\n",
    "# https://github.com/zalandoresearch/fashion-mnist\n",
    "index_to_label = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\",\n",
    "}\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "# train_imgs = x_train.reshape((60000,28,28))\n",
    "train_imgs = x_train.reshape((-1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d4ff3f",
   "metadata": {},
   "source": [
    "# What is matrix multiplication?\n",
    "\n",
    "Before we get too far down the road with implementing this, it's worth just\n",
    "revising what's happening with matrix multiplication. I rewatched [part of the\n",
    "Khan Academy introduction to this topic](https://youtu.be/kT4Mp9EdVqs) and I was\n",
    "really glad that I did because it mentions that the way we do matrix\n",
    "multiplication is a convention that's agreed upon by mathematicians and those\n",
    "who've used it over time. Until now, I never really understood why we did it\n",
    "this way; I'm sure there's a good reason, but without this context that it's\n",
    "just something that's been agreed upon, I was always a bit confused.\n",
    "\n",
    "A very simple matrix multiplication may be represented as follows, and I hope\n",
    "it's clear in the stages what's going on here. Note that in Python this would be\n",
    "represented as arrays of arrays, but I'm using the mathematical notation here\n",
    "following how it's demonstrated in the video.\n",
    "\n",
    "![Basic matrix multiplication](./images/part2-lesson11/basic-matmul-hand-drawn.png)\n",
    "\n",
    "(1) shows the two matrices that we're going to multiply together. We're starting\n",
    "with some really simple 2x2 matrices to make it clear what's happening.\n",
    "(2) shows the calculations that are going on underneath when we 'do matrix\n",
    "multiplication'. Again, this is just a convention that's been agreed upon by the\n",
    "people that do matrix multiplication and it doesn't necessarily need to make\n",
    "sense at the moment in terms of why they chose to do it this way.\n",
    "(3) shows the final result from the calculation.\n",
    "\n",
    "Note that there is [this website](http://matrixmultiplication.xyz) that also\n",
    "attempts to show what's happening, but I never found it particularly helpful for\n",
    "me to understand, except the part where we visualise the second matrix being\n",
    "rotated on its side. YMMV.\n",
    "\n",
    "Also, if you want to do this using APL, it's pretty easy to do these kinds of\n",
    "multiplication, with a notation that is very compact:\n",
    "\n",
    "```\n",
    "    M ← 2 2 ⍴ 2 3 6 9\n",
    "    N ← 2 2 ⍴ 2 1 3 6\n",
    "\n",
    "    M +.× N\n",
    "13 20\n",
    "39 60\n",
    "```\n",
    "\n",
    "We first assign the matrices to variables `M` and `N`, and then we do the\n",
    "multiplication which gives us the same result as when we did it by hand.\n",
    "\n",
    "To do the same in Python takes a bit more effort. I'll show it with arrays first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be61e98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[13, 20], [39, 60]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = [[2, 3], [6, 9]]\n",
    "N = [[2, 1], [3, 6]]\n",
    "\n",
    "def matmul_array(a1, a2):\n",
    "    result = [[0, 0], [0, 0]]\n",
    "    for i in range(len(a1)):\n",
    "        for j in range(len(a2[0])):\n",
    "            for k in range(len(a2)):\n",
    "                result[i][j] += a1[i][k] * a2[k][j]\n",
    "    return result\n",
    "\n",
    "matmul_array(M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe81e978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 1e+03 ns, total: 10 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "# to benchmark this against other implementations\n",
    "%time _=matmul_array(M, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061338d8",
   "metadata": {},
   "source": [
    "We can do the same thing using PyTorch, since we're allowed to use it as per the\n",
    "rules of the game here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f7c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = tensor([[2, 3], [6, 9]])\n",
    "N = tensor([[2, 1], [3, 6]])\n",
    "\n",
    "def matmul_tensor(a1, a2):\n",
    "    result = torch.zeros(len(a1), len(a2[0]))\n",
    "    for i in range(len(a1)):\n",
    "        for j in range(len(a2[0])):\n",
    "            for k in range(len(a2)):\n",
    "                result[i][j] += a1[i][k] * a2[k][j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c42973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13., 20.],\n",
       "        [39., 60.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul_tensor(M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cabcb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 ms, sys: 930 µs, total: 2.06 ms\n",
      "Wall time: 1.31 ms\n"
     ]
    }
   ],
   "source": [
    "# to benchmark this against other implementations\n",
    "%time _=matmul_tensor(M, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b485a",
   "metadata": {},
   "source": [
    "It is considerably slower using PyTorch, which I suppose is the penalty you pay\n",
    "immediately when doing things with an imported library rather than something\n",
    "built-in and using one of the core Python primitives (i.e. arrays).\n",
    "\n",
    "To demonstrate this one final time, we can do some multiplication using the\n",
    "Fashion-MNIST data we loaded in during the previous post and class. To simulate\n",
    "what happens early on when trying to fit our model to our data, we'll multiply\n",
    "a subset of our data by a matrix of random digits (which is what we begin with\n",
    "when we start the process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "756d75f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 784 is our 28x28 matrix flattened out, and 10 is the number of classes\n",
    "weights = torch.randn(784, 10)\n",
    "\n",
    "# we'll take 5 images\n",
    "imgs_subset = x_train[:5]\n",
    "\n",
    "# just to confirm the shapes of these tensors\n",
    "imgs_subset.shape, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc258532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.5 s, sys: 87.2 ms, total: 42.5 s\n",
      "Wall time: 44.6 s\n"
     ]
    }
   ],
   "source": [
    "%time _=matmul_tensor(weights, imgs_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38cc2a3",
   "metadata": {},
   "source": [
    "I'm just running this on my CPU, so it's going to take a while to run, but\n",
    "nevertheless it's a good demonstration of just how slow this way of running\n",
    "things is. It takes over 40 seconds to run the multiplication for just this\n",
    "small subset of 5 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754a7901",
   "metadata": {},
   "source": [
    "# Speed things up with Numba\n",
    "\n",
    "Using numba is a way to speed up Python code by pre-compiling it to machine\n",
    "code. The first time you run your numba-optimised code, it runs just at normal\n",
    "speed, but then when you run it again you'll see the speed improvement.\n",
    "\n",
    "It runs with numpy arrays, so we can use the same code as before, but using\n",
    "those arrays instead of tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca9afd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def dot_product(a, b):\n",
    "    result = 0.\n",
    "    for i in range(len(a)):\n",
    "        result += a[i] * b[i]\n",
    "    return result\n",
    "\n",
    "def matmul_numba(a1, a2):\n",
    "    result = torch.zeros(len(a1), len(a2[0]))\n",
    "    for i in range(len(a1)):\n",
    "        for j in range(len(a2[0])):\n",
    "            result[i][j] = dot_product(a1[i,:], a2[:, j])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "784091c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 784 is our 28x28 matrix flattened out, and 10 is the number of classes\n",
    "weights_np = torch.randn(784, 10).numpy()\n",
    "\n",
    "# we'll take 5 images\n",
    "imgs_subset_np = x_train[:5].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3ac87c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.91 s, sys: 39.5 ms, total: 3.95 s\n",
      "Wall time: 4.02 s\n"
     ]
    }
   ],
   "source": [
    "# first time\n",
    "%time _=matmul_numba(weights_np, imgs_subset_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abfef455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.57 s, sys: 7.74 ms, total: 3.58 s\n",
      "Wall time: 3.58 s\n"
     ]
    }
   ],
   "source": [
    "# second time\n",
    "%time _=matmul_numba(weights_np, imgs_subset_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92629e01",
   "metadata": {},
   "source": [
    "Interestingly, this doesn't actually bring much of a speed increase on my\n",
    "machine, but I do see if it I am multiplying a trivial matrix of 3x1:\n",
    "\n",
    "```python\n",
    "%time dot_product(array([1.,2,3]),array([2.,3,4]))\n",
    "```\n",
    "\n",
    "This brings a speed up from a few hundred miliseconds to a few tens of\n",
    "microseconds. My hypothesis is that the memory constraints of the bigger\n",
    "calculation become the bottleneck at that point and thus there's nothing that\n",
    "numba can do to help with that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedd3889",
   "metadata": {},
   "source": [
    "# Elementwise operations\n",
    "\n",
    "We can also do elementwise operations on tensors. In the lecture we see this\n",
    "easily demonstrated in APL, but we can do the same thing in Python. The\n",
    "advantage of doing it in a language like APL is that it's very compact and you\n",
    "can spend more time thinking about what you're actually trying to do instead of\n",
    "writing boilerplate code.\n",
    "\n",
    "For our matrix multiplication, we can replace our innermost loop (in which we\n",
    "multiply all the pairs of values) with an elementwise multiplication. With this\n",
    "replacement, we just use the corresponding code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e562422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_elementwise(a, b):\n",
    "    result = torch.zeros(len(a), len(b[0]))\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(b[0])):\n",
    "            result[i, j] = (a[i, :] * b[:, j]).sum()  # elementwise\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a2fa0",
   "metadata": {},
   "source": [
    "When trying to run our `matmul_elementwise` in a notebook on the Fashion-MNIST data, I get an error\n",
    "at this point, because our two tensors do not have the right dimensions to work\n",
    "together in this reformulation:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "RuntimeError                              Traceback (most recent call last)\n",
    "Cell In [21], line 1\n",
    "----> 1 matmul_elementwise(weights, imgs_subset)\n",
    "\n",
    "Cell In [20], line 5, in matmul_elementwise(a, b)\n",
    "      3 for i in range(len(a)):\n",
    "      4     for j in range(len(b[0])):\n",
    "----> 5         result[i, j] = (a[i, :] * b[:, j]).sum(dim=0)  # elementwise\n",
    "      6 return result\n",
    "\n",
    "RuntimeError: The size of tensor a (10) must match the size of tensor b (5) at non-singleton dimension 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2f061c",
   "metadata": {},
   "source": [
    "You can run it on matrices with shapes that work together for this operation. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6ece1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58.,  64.],\n",
       "        [139., 154.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = tensor([[1., 2, 3], [4, 5, 6]])\n",
    "m2 = tensor([[7., 8], [9, 10], [11, 12]])\n",
    "\n",
    "matmul_elementwise(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fccaaf5",
   "metadata": {},
   "source": [
    "But what if they don't match? What if you want to multiply a vector by a matrix,\n",
    "where you want to simply repeat the vector values repeated over and over for the\n",
    "number of rows in the matrix? For that we'll need to learn about broadcasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003b6afb",
   "metadata": {},
   "source": [
    "# Broadcasting to fill in the blanks\n",
    "\n",
    "Broadcasting is what you use when you have two tensors that don't have the same\n",
    "shape. Not only do you want this mismatched pair to work together (i.e. be\n",
    "multiplied or whatever you are trying to achieve), but you want to do it in a\n",
    "way that is as efficient as possible. Broadcasting is how we do this, where a\n",
    "sort of ghost copy of whatever we specify is 'broadcast' over the other tensor\n",
    "to make it work.\n",
    "\n",
    "The easiest way to see this in action (as Jeremy demonstrates in the lecture) is\n",
    "to specify something once that you want to be applied across the whole vector.\n",
    "Here, we want to get a tensor of the same shape as `e`, but that contains\n",
    "boolean values depending on whether the individual values are less than 2 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "450a1b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = tensor([1., 2, 3])\n",
    "e < 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43adfdcd",
   "metadata": {},
   "source": [
    "We didn't need to specify that the `e < 2` calculation needed to be applied to\n",
    "every element, but rather it was broadcast across the values in the vector, as\n",
    "if what we were passing in for the comparison was `tensor([2., 2., 2.,])` so\n",
    "that it could make the comparison.\n",
    "\n",
    "When broadcasting happens, the tensor with the smaller number of dimensions is\n",
    "not literally copied multiple times in memory, but rather the comparison is\n",
    "handled without needing to do that. This is what makes broadcasting so\n",
    "efficient.\n",
    "\n",
    "We don't need to confine ourselves to simple examples like this, however.\n",
    "Broadcasting works across multiple dimensions, such that we could, for example,\n",
    "multiply a matrix by a vector, where the vector is broadcast across the rows of\n",
    "the matrix.\n",
    "\n",
    "If you want to see what's going on under the hood, you can use the helpful `expand_as` method to see what the tensor looks like after it's been broadcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ac466f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tensor([10., 20, 30])\n",
    "m = tensor([[1., 2, 3], [4, 5, 6]])\n",
    "\n",
    "v.expand_as(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438acdc2",
   "metadata": {},
   "source": [
    "Here you can see that the vector has been broadcast across the rows of the\n",
    "matrix `m`. This is what allows us to do elementwise multiplication of the two\n",
    "tensors as in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a52336b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v + m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff95139",
   "metadata": {},
   "source": [
    "To learn more about `expand_as` we can take a look at the [PyTorch\n",
    "documentation](https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html#torch.Tensor.expand).\n",
    "It includes the useful warning that inplace operations using these\n",
    "ghost/broadcast 'copies' of values can lead to unexpected results and thus it's\n",
    "not encouraged.\n",
    "\n",
    "To see what is being stored in memory when we broadcast, we can use the\n",
    "`storage` method. Here you see that the vector is not actually being copied but\n",
    "rather we're just getting a reference to the same memory location for those\n",
    "three values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed6e3918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10.0\n",
       " 20.0\n",
       " 30.0\n",
       "[torch.storage._TypedStorage(dtype=torch.float32, device=cpu) of size 3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.expand_as(m).storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233df56",
   "metadata": {},
   "source": [
    "All of this is enabled using something called a 'stride'. A stride is the number\n",
    "of elements that you need to skip in order to get to the next element in a\n",
    "particular dimension. For example, with a stride of 1 for an array then each\n",
    "element is followed one by another.\n",
    "\n",
    "For a matrix, as in the example given by the PyTorch documentation, the stride\n",
    "tuple value tells us how many elements are in each row and then how to iterate\n",
    "through the elements in the rows (i.e. one by one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b59556b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
    "x.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6184ead9",
   "metadata": {},
   "source": [
    "It seems that what is happening is that the underlying data structure (i.e. the\n",
    "things you see when you call `storage`) is an array (or an array-like object),\n",
    "and that `stride` is used to construct how the array is interpreted as a\n",
    "tensor. The docs explain that `stride` is used in indexing operations, so if you\n",
    "index into your tensor, then it uses the values in `stride` to figure out what\n",
    "to pull out from the tensor. (If you want to learn more about `stride` and\n",
    "`storage`, check out [this useful blogpost](https://zhang-yang.medium.com/explain-pytorch-tensor-stride-and-tensor-storage-with-code-examples-50e637f1076d) with examples.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2674852",
   "metadata": {},
   "source": [
    "Bringing it back to broadcasting, `stride` is the trick used to make it so that\n",
    "it seems like the vector (or whatever) is being copied across the rows of the\n",
    "matrix, but in reality it's just a reference to the same memory location. So\n",
    "what happens is that the `stride` is set to 0 for the dimension that is being broadcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a583346d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a stride of zero meaning that it'll be broadcast\n",
    "v.expand_as(m).stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b127eec6",
   "metadata": {},
   "source": [
    "# Unsqueeze yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c0f9dc",
   "metadata": {},
   "source": [
    "We can use unsqueeze to add a dimension to a tensor. For example, if we have a\n",
    "scalar, we can turn it into a vector by adding a dimension to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1a28bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1]), tensor([[1, 2, 3]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(1).unsqueeze(0), tensor([1, 2, 3]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e643651c",
   "metadata": {},
   "source": [
    "There we were adding a dimension to a scalar, and to a vector. Alternatively, we\n",
    "can use the following notation to achieve the same effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1348374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([1, 2, 3])[None, :]\n",
    "tensor([1, 2, 3])[None] # same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3a254d",
   "metadata": {},
   "source": [
    "Here, we are indexing into our tensor using the special value `None`, which (if\n",
    "you do this) means that a new dimension gets added to the tensor. Note that you\n",
    "could do this more than one time and then you'll get more dimensions added. This\n",
    "is equivalent to `tensor([1, 2, 3]).unsqueeze(0).unsqueeze(0)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a39fcb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([1, 2, 3])[None, None, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d841436",
   "metadata": {},
   "source": [
    "If we want to do this by column instead of by row, we can add the new dimension\n",
    "across the columns as well by either passing in the dimension into `unsqueeze`\n",
    "or by using the `None` notation but indexing into the columns instead of the\n",
    "rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae7ec786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([1, 2, 3])[:, None]\n",
    "tensor([1, 2, 3]).unsqueeze(1) # these are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b850a624",
   "metadata": {},
   "source": [
    "If you have multiple dimensions and you want to use the `None` notation, you can\n",
    "use `...` to refer to the dimensions that you don't want to specify. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a9a7111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1],\n",
       "          [2],\n",
       "          [3]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([[[1, 2, 3]]])[..., None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aa9b47",
   "metadata": {},
   "source": [
    "The key thing to remember is that broadcasting is handling a lot of the heavy\n",
    "lifting here. You don't need to manually 'expand' vectors so that they match the\n",
    "matrices that you're trying to use them with. This happens automagically and\n",
    "PyTorch (or numpy) handles all that for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e09c30",
   "metadata": {},
   "source": [
    "# Broadcasting for matrix multiplication\n",
    "\n",
    "We now have all the pieces we need to use broadcasting in our function to do\n",
    "matrix multiplication. We just redefine the function to use broadcasting and\n",
    "then we can use it on any two matrices that are compatible for multiplication.\n",
    "(In the lesson, Jeremy goes through the rules of what makes for a compatible\n",
    "tensor, but for now we just say that the dimensions should either be equal or\n",
    "one of the dimensions should be 1 for broadcasting to work / apply. We start at\n",
    "the trailing (i.e. last) dimension and work our way backwards.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ae60f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_broadcast(a, b):\n",
    "    result = torch.zeros(len(a), len(b[0]))\n",
    "    for i in range(len(a)):\n",
    "        result[i] = (a[i, :, None] * b).sum(dim=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4355c00",
   "metadata": {},
   "source": [
    "Note that we have managed to reduce the number of loops down to a single one. We\n",
    "expand `a` so that it is the same shape as `b`, and then we can do elementwise\n",
    "multiplication and summing over the columns. This current implementation works\n",
    "for the case that we're trying to implement, but I'm not sure if it would work\n",
    "for higher dimensions. (Question: does matrix multiplication even make sense at\n",
    "higher dimensions? Are there conventions around that?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53c9e5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58.,  64.],\n",
       "        [139., 154.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = tensor([[1, 2, 3], [4, 5, 6]])\n",
    "m2 = tensor([[7, 8], [9, 10], [11, 12]])\n",
    "matmul_broadcast(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231a90d",
   "metadata": {},
   "source": [
    "In the case of our images, we have a batch of 60,000 images, each of which is\n",
    "28x28 (flattened down to a vector of 784 individual pixel values). Our weights\n",
    "matrix is 784x10, because we have 10 classes that we're trying to predict and\n",
    "for each class we have a set of weights for each of the 784 pixels. (Think of\n",
    "the 'ideal' image for each class as what those weights would be.)\n",
    "\n",
    "So in our matrix multiplication over the full set, we loop over each image of\n",
    "the 60,000, then for each one we will do a matrix multiplication where we have\n",
    "784x10 so that they work together. These values are then summed up as per the\n",
    "convention for this kind of calculation. In the end, we get a tensor of 60000x10\n",
    "which is what we were hoping to achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d2ef2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.4 s, sys: 6.45 ms, total: 1.41 s\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%time _=matmul_broadcast(x_train, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c00ad191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18824ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matmul_broadcast(x_train, weights).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec0b34",
   "metadata": {},
   "source": [
    "Broadcasting is, as Jeremy emphasised in the class, a really important concept\n",
    "and technique used all the time in what we're doing, so it pays to be familiar\n",
    "with it. The [numpy docs explainer on\n",
    "broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html) is\n",
    "really great, with some nice illustrations and examples, so I'd recommend\n",
    "checking that out to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49129039",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "\n",
    "- Dot product: this is the sum of the products of the paired elements of two\n",
    "  vectors or arrays. It is sometimes known as the scalar product.\n",
    "- Frobenius norm: this is the square root of the sum of the squares of the\n",
    "  elements of a matrix. It is sometimes known as the Euclidean norm.\n",
    "- Outer product: this is the product of two vectors, where the result is a\n",
    "  matrix. It is sometimes known as the tensor product. So if you have two\n",
    "  tensors with shapes `(3,)` and `(4,)` then the outer product will be a tensor\n",
    "  with shape `(3, 4)`.\n",
    "- Scalar: a single number, as opposed to a vector or matrix.\n",
    "- Stride: the number of elements that you need to skip in order to get to the\n",
    "  next element in a particular dimension.\n",
    "- Trailing dimension: the last dimension of a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3059da03-c65b-4ad6-a93e-de0aa10f40f1",
   "metadata": {},
   "source": [
    "# \"Things Jeremy says to do\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5e514-f496-49ea-a9b8-b7169eafe419",
   "metadata": {},
   "source": [
    "I thought I'd gather some of the core 'things Jeremy says to do' comments from\n",
    "the video lecture for this part of the lecture.\n",
    "\n",
    "- develop your intuition around concepts and code in the notebook, but then once\n",
    "  you've reached a point where you have something working, copy the code cells above\n",
    "  and turn it (minus the comments and markdown) into a function. ([link](https://youtu.be/Tf-8F5q8Xww?t=4039))\n",
    "    - keep the stuff above it, though, so you can how you reached that final\n",
    "      point\n",
    "- if you're refactoring your code, make sure that the new / refactored code that\n",
    "  you write is giving the same results as the slower / pre-refactoring code.\n",
    "  Jeremy uses the `test_close` function from `fastcore.test` to do this.\n",
    "  ([link](https://youtu.be/Tf-8F5q8Xww?t=4292))\n",
    "- if you're new to something, experiment with it in a notebook to cement your understanding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('fastai-part2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c21b828e62dd44be23831f29528317213925c35b98cb16b207582126ec6e1919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
