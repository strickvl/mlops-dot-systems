<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Alex Strick van Linschoten">
<meta name="dcterms.date" content="2022-10-29">
<meta name="description" content="Notes and some personal exploration following through the lesson 11 course materials from FastAI part 2. We covered various ways to multiply matrices in Python, in increasing order of performance.">

<title>Alex Strick van Linschoten - Matrix multiplication and broadcasting from the foundations</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script defer="" data-domain="alexstrick.com" src="https://plausible.io/js/script.js"></script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Alex Strick van Linschoten - Matrix multiplication and broadcasting from the foundations">
<meta property="og:description" content="Notes and some personal exploration following through the lesson 11 course materials from FastAI part 2. We covered various ways to multiply matrices in Python, in increasing order of performance.">
<meta property="og:image" content="https://alexstrick.com/posts/AWAITING_COURSE_RELEASE/images/part2-lesson11/matmul-cover.png">
<meta property="og:site-name" content="Alex Strick van Linschoten">
<meta name="twitter:title" content="Alex Strick van Linschoten - Matrix multiplication and broadcasting from the foundations">
<meta name="twitter:description" content="Notes and some personal exploration following through the lesson 11 course materials from FastAI part 2. We covered various ways to multiply matrices in Python, in increasing order of performance.">
<meta name="twitter:image" content="https://alexstrick.com/posts/AWAITING_COURSE_RELEASE/images/part2-lesson11/matmul-cover.png">
<meta name="twitter:creator" content="@strickvl">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Alex Strick van Linschoten</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text">Technical</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../personal.html">
 <span class="menu-text">Personal</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../til.html">
 <span class="menu-text">TIL</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/strickvl"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://sigmoid.social/web/@alexstrick"><i class="bi bi-mastodon" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/strickvl"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-rss" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">RSS</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-rss">    
        <li>
    <a class="dropdown-item" href="../../index.xml">
 <span class="dropdown-text">Technical RSS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../personal.xml">
 <span class="dropdown-text">Personal RSS</span></a>
  </li>  
    </ul>
  </li>
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Matrix multiplication and broadcasting from the foundations</h1>
                  <div>
        <div class="description">
          Notes and some personal exploration following through the lesson 11 course materials from FastAI part 2. We covered various ways to multiply matrices in Python, in increasing order of performance.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">computervision</div>
                <div class="quarto-category">fastai</div>
                <div class="quarto-category">parttwo</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Alex Strick van Linschoten </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 29, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#what-is-matrix-multiplication" id="toc-what-is-matrix-multiplication" class="nav-link active" data-scroll-target="#what-is-matrix-multiplication">What is matrix multiplication?</a></li>
  <li><a href="#speed-things-up-with-numba" id="toc-speed-things-up-with-numba" class="nav-link" data-scroll-target="#speed-things-up-with-numba">Speed things up with Numba</a></li>
  <li><a href="#elementwise-operations" id="toc-elementwise-operations" class="nav-link" data-scroll-target="#elementwise-operations">Elementwise operations</a></li>
  <li><a href="#broadcasting-to-fill-in-the-blanks" id="toc-broadcasting-to-fill-in-the-blanks" class="nav-link" data-scroll-target="#broadcasting-to-fill-in-the-blanks">Broadcasting to fill in the blanks</a></li>
  <li><a href="#unsqueeze-yourself" id="toc-unsqueeze-yourself" class="nav-link" data-scroll-target="#unsqueeze-yourself">Unsqueeze yourself</a></li>
  <li><a href="#broadcasting-for-matrix-multiplication" id="toc-broadcasting-for-matrix-multiplication" class="nav-link" data-scroll-target="#broadcasting-for-matrix-multiplication">Broadcasting for matrix multiplication</a></li>
  <li><a href="#definitions" id="toc-definitions" class="nav-link" data-scroll-target="#definitions">Definitions</a></li>
  <li><a href="#things-jeremy-says-to-do" id="toc-things-jeremy-says-to-do" class="nav-link" data-scroll-target="#things-jeremy-says-to-do">“Things Jeremy says to do”</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>(<em>This is part of a series of blog posts relating to and responding to the live FastAI course (part 2) being taught in late 2022. To read others, see the ones listed for <a href="https://mlops.systems/#category=parttwo">the ‘parttwo’ tag</a>.</em>)</p>
<p>This week in the second half of the class we covered matrix multiplication and broadcasting. (I’ll write a separate blog about the parts of lessons 9-11 where we discuss specific papers.) These two concepts are important because machine learning (and deep learning especially) is all about operations on matrices and vectors, so we both had best understand the concepts but also be able to make those calculations quickly and efficiently.</p>
<p>At the bottom of this post, I’ll also include my collation of the “Things Jeremy says to do” from this lesson. The relevant topics and libraries covered in this lecture are linked below.</p>
<table class="table">
<thead>
<tr class="header">
<th>MetaTask</th>
<th>Subtask</th>
<th>Concept / Skill</th>
<th>Docs / Link</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Multiply matrices</td>
<td>Implement basic matrix multiplication</td>
<td>Matrix multiplication</td>
<td><a href="https://youtu.be/kT4Mp9EdVqs">link</a></td>
</tr>
<tr class="even">
<td></td>
<td>Pre-compile using numba</td>
<td>Numba conversion</td>
<td><a href="https://numba.pydata.org">link</a></td>
</tr>
<tr class="odd">
<td></td>
<td>Use elementwise ops</td>
<td>APL</td>
<td><a href="https://tryapl.org">link</a></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>Frobenius norm</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>Broadcast to match up matrices</td>
<td>Broadcasting</td>
<td><a href="https://numpy.org/doc/stable/user/basics.broadcasting.html">link</a> / <a href="https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics">link</a></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td><code>expand_as</code></td>
<td><a href="https://pytorch.org/docs/stable/generated/torch.Tensor.expand_as.html">link</a> / <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html#torch.Tensor.expand">link</a></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td><code>storage</code></td>
<td><a href="https://pytorch.org/docs/stable/generated/torch.Tensor.storage.html">link</a></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>stride</td>
<td><a href="https://pytorch.org/docs/stable/generated/torch.Tensor.stride.html">link</a></td>
</tr>
<tr class="odd">
<td></td>
<td>Adding dimensions</td>
<td><code>unsqueeze</code></td>
<td><a href="https://pytorch.org/docs/stable/generated/torch.unsqueeze.html">link</a></td>
</tr>
</tbody>
</table>
<p>Before we get into the things we’re doing with matrix multiplication, I’m including the code from <a href="https://mlops.systems/computervision/fastai/parttwo/2022/10/24/foundations-mnist-basics.html">the previous post</a> so that the variables are available to us in this notebook, but hiding the cell so that it doesn’t distract from the main content.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#collapse-hide</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib <span class="im">as</span> mpl, matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> tensor</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gzip</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> urllib.request <span class="im">import</span> urlretrieve</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> functools</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> operator</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> struct</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> array</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tempfile</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>torch.set_printoptions(precision<span class="op">=</span><span class="dv">2</span>, linewidth<span class="op">=</span><span class="dv">140</span>, sci_mode<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>BASE_URL <span class="op">=</span> <span class="st">"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/"</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>TRAINING_IMAGES <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>BASE_URL<span class="sc">}</span><span class="ss">train-images-idx3-ubyte.gz"</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>TRAINING_IMAGES_LABELS <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>BASE_URL<span class="sc">}</span><span class="ss">train-labels-idx1-ubyte.gz"</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>TEST_IMAGES <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>BASE_URL<span class="sc">}</span><span class="ss">t10k-images-idx3-ubyte.gz"</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>TEST_IMAGES_LABELS <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>BASE_URL<span class="sc">}</span><span class="ss">t10k-labels-idx1-ubyte.gz"</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># create local path directory if it doesn't exist</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>LOCAL_PATH <span class="op">=</span> Path(<span class="st">"data"</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co"># check whether the path exists; create it if it doesn't exist</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> LOCAL_PATH.exists():</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    LOCAL_PATH.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>training_images_path <span class="op">=</span> LOCAL_PATH <span class="op">/</span> <span class="st">"train-images-idx3-ubyte.gz"</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>training_images_labels_path <span class="op">=</span> LOCAL_PATH <span class="op">/</span> <span class="st">"train-labels-idx1-ubyte.gz"</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>test_images_path <span class="op">=</span> LOCAL_PATH <span class="op">/</span> <span class="st">"t10k-images-idx3-ubyte.gz"</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>test_images_labels_path <span class="op">=</span> LOCAL_PATH <span class="op">/</span> <span class="st">"t10k-labels-idx1-ubyte.gz"</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co"># download the raw data if it doesn't exist</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> training_images_path.exists():</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    urlretrieve(TRAINING_IMAGES, training_images_path)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> training_images_labels_path.exists():</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    urlretrieve(TRAINING_IMAGES_LABELS, training_images_labels_path)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> test_images_path.exists():</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    urlretrieve(TEST_IMAGES, test_images_path)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> test_images_labels_path.exists():</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    urlretrieve(TEST_IMAGES_LABELS, test_images_labels_path)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co"># taken from https://github.com/datapythonista/mnist/blob/master/mnist/__init__.py</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parse_idx(fd):</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Parse an IDX file, and return it as an array of arrays.</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co">    fd : file</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="co">        File descriptor of the IDX file to parse</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="co">    endian : str</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="co">        Byte order of the IDX file. See [1] for available options</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="co">    data : array</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="co">        Numpy array with the dimensions and the data in the IDX file</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="co">    1. https://docs.python.org/3/library/struct.html</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="co">        #byte-order-size-and-alignment</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>    DATA_TYPES <span class="op">=</span> {</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>        <span class="bn">0x08</span>: <span class="st">"B"</span>,  <span class="co"># unsigned byte</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>        <span class="bn">0x09</span>: <span class="st">"b"</span>,  <span class="co"># signed byte</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>        <span class="bn">0x0B</span>: <span class="st">"h"</span>,  <span class="co"># short (2 bytes)</span></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>        <span class="bn">0x0C</span>: <span class="st">"i"</span>,  <span class="co"># int (4 bytes)</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>        <span class="bn">0x0D</span>: <span class="st">"f"</span>,  <span class="co"># float (4 bytes)</span></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>        <span class="bn">0x0E</span>: <span class="st">"d"</span>,</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>    }  <span class="co"># double (8 bytes)</span></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>    header <span class="op">=</span> fd.read(<span class="dv">4</span>)</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(header) <span class="op">!=</span> <span class="dv">4</span>:</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> IdxDecodeError(</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Invalid IDX file, "</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>            <span class="st">"file empty or does not contain a full header."</span></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>    zeros, data_type, num_dimensions <span class="op">=</span> struct.unpack(<span class="st">"&gt;HBB"</span>, header)</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> zeros <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> IdxDecodeError(</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Invalid IDX file, "</span></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>            <span class="st">"file must start with two zero bytes. "</span></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Found 0x</span><span class="sc">%02x</span><span class="st">"</span> <span class="op">%</span> zeros</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>        data_type <span class="op">=</span> DATA_TYPES[data_type]</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">KeyError</span>:</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> IdxDecodeError(</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Unknown data type "</span> <span class="st">"0x</span><span class="sc">%02x</span><span class="st"> in IDX file"</span> <span class="op">%</span> data_type</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>    dimension_sizes <span class="op">=</span> struct.unpack(</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>        <span class="st">"&gt;"</span> <span class="op">+</span> <span class="st">"I"</span> <span class="op">*</span> num_dimensions, fd.read(<span class="dv">4</span> <span class="op">*</span> num_dimensions)</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> array.array(data_type, fd.read())</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>    data.byteswap()  <span class="co"># looks like array.array reads data as little endian</span></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>    expected_items <span class="op">=</span> functools.<span class="bu">reduce</span>(operator.mul, dimension_sizes)</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(data) <span class="op">!=</span> expected_items:</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> IdxDecodeError(</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>            <span class="st">"IDX file has wrong number of items. "</span></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Expected: </span><span class="sc">%d</span><span class="st">. Found: </span><span class="sc">%d</span><span class="st">"</span> <span class="op">%</span> (expected_items, <span class="bu">len</span>(data))</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="co"># chunk things together</span></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> chunks(x, size):</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(x), size):</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> x[i : i <span class="op">+</span> size]</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a><span class="co"># unzip the files and extract the images</span></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> gzip.<span class="bu">open</span>(training_images_path, <span class="st">"rb"</span>) <span class="im">as</span> f:</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>    pixels <span class="op">=</span> <span class="bu">list</span>(parse_idx(f))</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>    x_train <span class="op">=</span> <span class="bu">list</span>(chunks(pixels, <span class="dv">784</span>))</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> gzip.<span class="bu">open</span>(training_images_labels_path, <span class="st">"rb"</span>) <span class="im">as</span> f:</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>    y_train <span class="op">=</span> <span class="bu">list</span>(parse_idx(f))</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> gzip.<span class="bu">open</span>(test_images_path, <span class="st">"rb"</span>) <span class="im">as</span> f:</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>    pixels <span class="op">=</span> <span class="bu">list</span>(parse_idx(f))</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>    x_valid <span class="op">=</span> <span class="bu">list</span>(chunks(pixels, <span class="dv">784</span>))</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> gzip.<span class="bu">open</span>(test_images_labels_path, <span class="st">"rb"</span>) <span class="im">as</span> f:</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>    y_valid <span class="op">=</span> <span class="bu">list</span>(parse_idx(f))</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a><span class="co"># this list is taken from the README of the Fashion-MNIST repository</span></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="co"># https://github.com/zalandoresearch/fashion-mnist</span></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>index_to_label <span class="op">=</span> {</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>    <span class="dv">0</span>: <span class="st">"T-shirt/top"</span>,</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span>: <span class="st">"Trouser"</span>,</span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2</span>: <span class="st">"Pullover"</span>,</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>    <span class="dv">3</span>: <span class="st">"Dress"</span>,</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a>    <span class="dv">4</span>: <span class="st">"Coat"</span>,</span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>    <span class="dv">5</span>: <span class="st">"Sandal"</span>,</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>    <span class="dv">6</span>: <span class="st">"Shirt"</span>,</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>    <span class="dv">7</span>: <span class="st">"Sneaker"</span>,</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>    <span class="dv">8</span>: <span class="st">"Bag"</span>,</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>    <span class="dv">9</span>: <span class="st">"Ankle boot"</span>,</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>x_train, y_train, x_valid, y_valid <span class="op">=</span> <span class="bu">map</span>(</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>    tensor, (x_train, y_train, x_valid, y_valid)</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a><span class="co"># train_imgs = x_train.reshape((60000,28,28))</span></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>train_imgs <span class="op">=</span> x_train.reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="what-is-matrix-multiplication" class="level1">
<h1>What is matrix multiplication?</h1>
<p>Before we get too far down the road with implementing this, it’s worth just revising what’s happening with matrix multiplication. I rewatched <a href="https://youtu.be/kT4Mp9EdVqs">part of the Khan Academy introduction to this topic</a> and I was really glad that I did because it mentions that the way we do matrix multiplication is a convention that’s agreed upon by mathematicians and those who’ve used it over time. Until now, I never really understood why we did it this way; I’m sure there’s a good reason, but without this context that it’s just something that’s been agreed upon, I was always a bit confused.</p>
<p>A very simple matrix multiplication may be represented as follows, and I hope it’s clear in the stages what’s going on here. Note that in Python this would be represented as arrays of arrays, but I’m using the mathematical notation here following how it’s demonstrated in the video.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/part2-lesson11/basic-matmul-hand-drawn.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Basic matrix multiplication</figcaption><p></p>
</figure>
</div>
<ol type="1">
<li>shows the two matrices that we’re going to multiply together. We’re starting with some really simple 2x2 matrices to make it clear what’s happening.</li>
<li>shows the calculations that are going on underneath when we ‘do matrix multiplication’. Again, this is just a convention that’s been agreed upon by the people that do matrix multiplication and it doesn’t necessarily need to make sense at the moment in terms of why they chose to do it this way.</li>
<li>shows the final result from the calculation.</li>
</ol>
<p>Note that there is <a href="http://matrixmultiplication.xyz">this website</a> that also attempts to show what’s happening, but I never found it particularly helpful for me to understand, except the part where we visualise the second matrix being rotated on its side. YMMV.</p>
<p>Also, if you want to do this using APL, it’s pretty easy to do these kinds of multiplication, with a notation that is very compact:</p>
<pre><code>    M ← 2 2 ⍴ 2 3 6 9
    N ← 2 2 ⍴ 2 1 3 6

    M +.× N
13 20
39 60</code></pre>
<p>We first assign the matrices to variables <code>M</code> and <code>N</code>, and then we do the multiplication which gives us the same result as when we did it by hand.</p>
<p>To do the same in Python takes a bit more effort. I’ll show it with arrays first.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>M <span class="op">=</span> [[<span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">6</span>, <span class="dv">9</span>]]</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> [[<span class="dv">2</span>, <span class="dv">1</span>], [<span class="dv">3</span>, <span class="dv">6</span>]]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> matmul_array(a1, a2):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> [[<span class="dv">0</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">0</span>]]</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(a1)):</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(a2[<span class="dv">0</span>])):</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(a2)):</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>                result[i][j] <span class="op">+=</span> a1[i][k] <span class="op">*</span> a2[k][j]</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>matmul_array(M, N)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>[[13, 20], [39, 60]]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to benchmark this against other implementations</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>time _<span class="op">=</span>matmul_array(M, N)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 9 µs, sys: 1e+03 ns, total: 10 µs
Wall time: 11 µs</code></pre>
</div>
</div>
<p>We can do the same thing using PyTorch, since we’re allowed to use it as per the rules of the game here:</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>M <span class="op">=</span> tensor([[<span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">6</span>, <span class="dv">9</span>]])</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> tensor([[<span class="dv">2</span>, <span class="dv">1</span>], [<span class="dv">3</span>, <span class="dv">6</span>]])</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> matmul_tensor(a1, a2):</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> torch.zeros(<span class="bu">len</span>(a1), <span class="bu">len</span>(a2[<span class="dv">0</span>]))</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(a1)):</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(a2[<span class="dv">0</span>])):</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(a2)):</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>                result[i][j] <span class="op">+=</span> a1[i][k] <span class="op">*</span> a2[k][j]</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>matmul_tensor(M, N)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>tensor([[13., 20.],
        [39., 60.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to benchmark this against other implementations</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>time _<span class="op">=</span>matmul_tensor(M, N)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1.13 ms, sys: 930 µs, total: 2.06 ms
Wall time: 1.31 ms</code></pre>
</div>
</div>
<p>It is considerably slower using PyTorch, which I suppose is the penalty you pay immediately when doing things with an imported library rather than something built-in and using one of the core Python primitives (i.e.&nbsp;arrays).</p>
<p>To demonstrate this one final time, we can do some multiplication using the Fashion-MNIST data we loaded in during the previous post and class. To simulate what happens early on when trying to fit our model to our data, we’ll multiply a subset of our data by a matrix of random digits (which is what we begin with when we start the process).</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 784 is our 28x28 matrix flattened out, and 10 is the number of classes</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> torch.randn(<span class="dv">784</span>, <span class="dv">10</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># we'll take 5 images</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>imgs_subset <span class="op">=</span> x_train[:<span class="dv">5</span>]</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co"># just to confirm the shapes of these tensors</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>imgs_subset.shape, weights.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>(torch.Size([5, 784]), torch.Size([784, 10]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>time _<span class="op">=</span>matmul_tensor(weights, imgs_subset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 42.5 s, sys: 87.2 ms, total: 42.5 s
Wall time: 44.6 s</code></pre>
</div>
</div>
<p>I’m just running this on my CPU, so it’s going to take a while to run, but nevertheless it’s a good demonstration of just how slow this way of running things is. It takes over 40 seconds to run the multiplication for just this small subset of 5 images.</p>
</section>
<section id="speed-things-up-with-numba" class="level1">
<h1>Speed things up with Numba</h1>
<p>Using numba is a way to speed up Python code by pre-compiling it to machine code. The first time you run your numba-optimised code, it runs just at normal speed, but then when you run it again you’ll see the speed improvement.</p>
<p>It runs with numpy arrays, so we can use the same code as before, but using those arrays instead of tensors.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numba <span class="im">import</span> njit</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="at">@njit</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dot_product(a, b):</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(a)):</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>        result <span class="op">+=</span> a[i] <span class="op">*</span> b[i]</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> matmul_numba(a1, a2):</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> torch.zeros(<span class="bu">len</span>(a1), <span class="bu">len</span>(a2[<span class="dv">0</span>]))</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(a1)):</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(a2[<span class="dv">0</span>])):</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>            result[i][j] <span class="op">=</span> dot_product(a1[i,:], a2[:, j])</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 784 is our 28x28 matrix flattened out, and 10 is the number of classes</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>weights_np <span class="op">=</span> torch.randn(<span class="dv">784</span>, <span class="dv">10</span>).numpy()</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># we'll take 5 images</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>imgs_subset_np <span class="op">=</span> x_train[:<span class="dv">5</span>].numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># first time</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>time _<span class="op">=</span>matmul_numba(weights_np, imgs_subset_np)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 3.91 s, sys: 39.5 ms, total: 3.95 s
Wall time: 4.02 s</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># second time</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>time _<span class="op">=</span>matmul_numba(weights_np, imgs_subset_np)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 3.57 s, sys: 7.74 ms, total: 3.58 s
Wall time: 3.58 s</code></pre>
</div>
</div>
<p>Interestingly, this doesn’t actually bring much of a speed increase on my machine, but I do see if it I am multiplying a trivial matrix of 3x1:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>time dot_product(array([<span class="fl">1.</span>,<span class="dv">2</span>,<span class="dv">3</span>]),array([<span class="fl">2.</span>,<span class="dv">3</span>,<span class="dv">4</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This brings a speed up from a few hundred miliseconds to a few tens of microseconds. My hypothesis is that the memory constraints of the bigger calculation become the bottleneck at that point and thus there’s nothing that numba can do to help with that.</p>
</section>
<section id="elementwise-operations" class="level1">
<h1>Elementwise operations</h1>
<p>We can also do elementwise operations on tensors. In the lecture we see this easily demonstrated in APL, but we can do the same thing in Python. The advantage of doing it in a language like APL is that it’s very compact and you can spend more time thinking about what you’re actually trying to do instead of writing boilerplate code.</p>
<p>For our matrix multiplication, we can replace our innermost loop (in which we multiply all the pairs of values) with an elementwise multiplication. With this replacement, we just use the corresponding code:</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> matmul_elementwise(a, b):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> torch.zeros(<span class="bu">len</span>(a), <span class="bu">len</span>(b[<span class="dv">0</span>]))</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(a)):</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(b[<span class="dv">0</span>])):</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>            result[i, j] <span class="op">=</span> (a[i, :] <span class="op">*</span> b[:, j]).<span class="bu">sum</span>()  <span class="co"># elementwise</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>When trying to run our <code>matmul_elementwise</code> in a notebook on the Fashion-MNIST data, I get an error at this point, because our two tensors do not have the right dimensions to work together in this reformulation:</p>
<pre><code>---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
Cell In [21], line 1
----&gt; 1 matmul_elementwise(weights, imgs_subset)

Cell In [20], line 5, in matmul_elementwise(a, b)
      3 for i in range(len(a)):
      4     for j in range(len(b[0])):
----&gt; 5         result[i, j] = (a[i, :] * b[:, j]).sum(dim=0)  # elementwise
      6 return result

RuntimeError: The size of tensor a (10) must match the size of tensor b (5) at non-singleton dimension 0</code></pre>
<p>You can run it on matrices with shapes that work together for this operation. For example:</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>m1 <span class="op">=</span> tensor([[<span class="fl">1.</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]])</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>m2 <span class="op">=</span> tensor([[<span class="fl">7.</span>, <span class="dv">8</span>], [<span class="dv">9</span>, <span class="dv">10</span>], [<span class="dv">11</span>, <span class="dv">12</span>]])</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>matmul_elementwise(m1, m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>tensor([[ 58.,  64.],
        [139., 154.]])</code></pre>
</div>
</div>
<p>But what if they don’t match? What if you want to multiply a vector by a matrix, where you want to simply repeat the vector values repeated over and over for the number of rows in the matrix? For that we’ll need to learn about broadcasting.</p>
</section>
<section id="broadcasting-to-fill-in-the-blanks" class="level1">
<h1>Broadcasting to fill in the blanks</h1>
<p>Broadcasting is what you use when you have two tensors that don’t have the same shape. Not only do you want this mismatched pair to work together (i.e.&nbsp;be multiplied or whatever you are trying to achieve), but you want to do it in a way that is as efficient as possible. Broadcasting is how we do this, where a sort of ghost copy of whatever we specify is ‘broadcast’ over the other tensor to make it work.</p>
<p>The easiest way to see this in action (as Jeremy demonstrates in the lecture) is to specify something once that you want to be applied across the whole vector. Here, we want to get a tensor of the same shape as <code>e</code>, but that contains boolean values depending on whether the individual values are less than 2 or not.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> tensor([<span class="fl">1.</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>e <span class="op">&lt;</span> <span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([ True, False, False])</code></pre>
</div>
</div>
<p>We didn’t need to specify that the <code>e &lt; 2</code> calculation needed to be applied to every element, but rather it was broadcast across the values in the vector, as if what we were passing in for the comparison was <code>tensor([2., 2., 2.,])</code> so that it could make the comparison.</p>
<p>When broadcasting happens, the tensor with the smaller number of dimensions is not literally copied multiple times in memory, but rather the comparison is handled without needing to do that. This is what makes broadcasting so efficient.</p>
<p>We don’t need to confine ourselves to simple examples like this, however. Broadcasting works across multiple dimensions, such that we could, for example, multiply a matrix by a vector, where the vector is broadcast across the rows of the matrix.</p>
<p>If you want to see what’s going on under the hood, you can use the helpful <code>expand_as</code> method to see what the tensor looks like after it’s been broadcast.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> tensor([<span class="fl">10.</span>, <span class="dv">20</span>, <span class="dv">30</span>])</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> tensor([[<span class="fl">1.</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]])</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>v.expand_as(m)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>tensor([[10., 20., 30.],
        [10., 20., 30.]])</code></pre>
</div>
</div>
<p>Here you can see that the vector has been broadcast across the rows of the matrix <code>m</code>. This is what allows us to do elementwise multiplication of the two tensors as in the following example:</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>v <span class="op">+</span> m</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor([[11., 22., 33.],
        [14., 25., 36.]])</code></pre>
</div>
</div>
<p>To learn more about <code>expand_as</code> we can take a look at the <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html#torch.Tensor.expand">PyTorch documentation</a>. It includes the useful warning that inplace operations using these ghost/broadcast ‘copies’ of values can lead to unexpected results and thus it’s not encouraged.</p>
<p>To see what is being stored in memory when we broadcast, we can use the <code>storage</code> method. Here you see that the vector is not actually being copied but rather we’re just getting a reference to the same memory location for those three values.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>v.expand_as(m).storage()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code> 10.0
 20.0
 30.0
[torch.storage._TypedStorage(dtype=torch.float32, device=cpu) of size 3]</code></pre>
</div>
</div>
<p>All of this is enabled using something called a ‘stride’. A stride is the number of elements that you need to skip in order to get to the next element in a particular dimension. For example, with a stride of 1 for an array then each element is followed one by another.</p>
<p>For a matrix, as in the example given by the PyTorch documentation, the stride tuple value tells us how many elements are in each row and then how to iterate through the elements in the rows (i.e.&nbsp;one by one):</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>], [<span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>]])</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>x.stride()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>(5, 1)</code></pre>
</div>
</div>
<p>It seems that what is happening is that the underlying data structure (i.e.&nbsp;the things you see when you call <code>storage</code>) is an array (or an array-like object), and that <code>stride</code> is used to construct how the array is interpreted as a tensor. The docs explain that <code>stride</code> is used in indexing operations, so if you index into your tensor, then it uses the values in <code>stride</code> to figure out what to pull out from the tensor. (If you want to learn more about <code>stride</code> and <code>storage</code>, check out <a href="https://zhang-yang.medium.com/explain-pytorch-tensor-stride-and-tensor-storage-with-code-examples-50e637f1076d">this useful blogpost</a> with examples.)</p>
<p>Bringing it back to broadcasting, <code>stride</code> is the trick used to make it so that it seems like the vector (or whatever) is being copied across the rows of the matrix, but in reality it’s just a reference to the same memory location. So what happens is that the <code>stride</code> is set to 0 for the dimension that is being broadcast.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># a stride of zero meaning that it'll be broadcast</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>v.expand_as(m).stride()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>(0, 1)</code></pre>
</div>
</div>
</section>
<section id="unsqueeze-yourself" class="level1">
<h1>Unsqueeze yourself</h1>
<p>We can use unsqueeze to add a dimension to a tensor. For example, if we have a scalar, we can turn it into a vector by adding a dimension to it.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>tensor(<span class="dv">1</span>).unsqueeze(<span class="dv">0</span>), tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]).unsqueeze(<span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>(tensor([1]), tensor([[1, 2, 3]]))</code></pre>
</div>
</div>
<p>There we were adding a dimension to a scalar, and to a vector. Alternatively, we can use the following notation to achieve the same effect:</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])[<span class="va">None</span>, :]</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])[<span class="va">None</span>] <span class="co"># same as above</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([[1, 2, 3]])</code></pre>
</div>
</div>
<p>Here, we are indexing into our tensor using the special value <code>None</code>, which (if you do this) means that a new dimension gets added to the tensor. Note that you could do this more than one time and then you’ll get more dimensions added. This is equivalent to <code>tensor([1, 2, 3]).unsqueeze(0).unsqueeze(0)</code>.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])[<span class="va">None</span>, <span class="va">None</span>, :]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([[[1, 2, 3]]])</code></pre>
</div>
</div>
<p>If we want to do this by column instead of by row, we can add the new dimension across the columns as well by either passing in the dimension into <code>unsqueeze</code> or by using the <code>None</code> notation but indexing into the columns instead of the rows.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])[:, <span class="va">None</span>]</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]).unsqueeze(<span class="dv">1</span>) <span class="co"># these are the same</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor([[1],
        [2],
        [3]])</code></pre>
</div>
</div>
<p>If you have multiple dimensions and you want to use the <code>None</code> notation, you can use <code>...</code> to refer to the dimensions that you don’t want to specify. For example:</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>tensor([[[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]]])[..., <span class="va">None</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>tensor([[[[1],
          [2],
          [3]]]])</code></pre>
</div>
</div>
<p>The key thing to remember is that broadcasting is handling a lot of the heavy lifting here. You don’t need to manually ‘expand’ vectors so that they match the matrices that you’re trying to use them with. This happens automagically and PyTorch (or numpy) handles all that for you.</p>
</section>
<section id="broadcasting-for-matrix-multiplication" class="level1">
<h1>Broadcasting for matrix multiplication</h1>
<p>We now have all the pieces we need to use broadcasting in our function to do matrix multiplication. We just redefine the function to use broadcasting and then we can use it on any two matrices that are compatible for multiplication. (In the lesson, Jeremy goes through the rules of what makes for a compatible tensor, but for now we just say that the dimensions should either be equal or one of the dimensions should be 1 for broadcasting to work / apply. We start at the trailing (i.e.&nbsp;last) dimension and work our way backwards.)</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> matmul_broadcast(a, b):</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> torch.zeros(<span class="bu">len</span>(a), <span class="bu">len</span>(b[<span class="dv">0</span>]))</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(a)):</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>        result[i] <span class="op">=</span> (a[i, :, <span class="va">None</span>] <span class="op">*</span> b).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that we have managed to reduce the number of loops down to a single one. We expand <code>a</code> so that it is the same shape as <code>b</code>, and then we can do elementwise multiplication and summing over the columns. This current implementation works for the case that we’re trying to implement, but I’m not sure if it would work for higher dimensions. (Question: does matrix multiplication even make sense at higher dimensions? Are there conventions around that?)</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>m1 <span class="op">=</span> tensor([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]])</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>m2 <span class="op">=</span> tensor([[<span class="dv">7</span>, <span class="dv">8</span>], [<span class="dv">9</span>, <span class="dv">10</span>], [<span class="dv">11</span>, <span class="dv">12</span>]])</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>matmul_broadcast(m1, m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([[ 58.,  64.],
        [139., 154.]])</code></pre>
</div>
</div>
<p>In the case of our images, we have a batch of 60,000 images, each of which is 28x28 (flattened down to a vector of 784 individual pixel values). Our weights matrix is 784x10, because we have 10 classes that we’re trying to predict and for each class we have a set of weights for each of the 784 pixels. (Think of the ‘ideal’ image for each class as what those weights would be.)</p>
<p>So in our matrix multiplication over the full set, we loop over each image of the 60,000, then for each one we will do a matrix multiplication where we have 784x10 so that they work together. These values are then summed up as per the convention for this kind of calculation. In the end, we get a tensor of 60000x10 which is what we were hoping to achieve.</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>time _<span class="op">=</span>matmul_broadcast(x_train, weights)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1.4 s, sys: 6.45 ms, total: 1.41 s
Wall time: 1.41 s</code></pre>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>x_train.shape, weights.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>(torch.Size([60000, 784]), torch.Size([784, 10]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>matmul_broadcast(x_train, weights).shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>torch.Size([60000, 10])</code></pre>
</div>
</div>
<p>Broadcasting is, as Jeremy emphasised in the class, a really important concept and technique used all the time in what we’re doing, so it pays to be familiar with it. The <a href="https://numpy.org/doc/stable/user/basics.broadcasting.html">numpy docs explainer on broadcasting</a> is really great, with some nice illustrations and examples, so I’d recommend checking that out to learn more.</p>
</section>
<section id="definitions" class="level1">
<h1>Definitions</h1>
<ul>
<li>Dot product: this is the sum of the products of the paired elements of two vectors or arrays. It is sometimes known as the scalar product.</li>
<li>Frobenius norm: this is the square root of the sum of the squares of the elements of a matrix. It is sometimes known as the Euclidean norm.</li>
<li>Outer product: this is the product of two vectors, where the result is a matrix. It is sometimes known as the tensor product. So if you have two tensors with shapes <code>(3,)</code> and <code>(4,)</code> then the outer product will be a tensor with shape <code>(3, 4)</code>.</li>
<li>Scalar: a single number, as opposed to a vector or matrix.</li>
<li>Stride: the number of elements that you need to skip in order to get to the next element in a particular dimension.</li>
<li>Trailing dimension: the last dimension of a tensor.</li>
</ul>
</section>
<section id="things-jeremy-says-to-do" class="level1">
<h1>“Things Jeremy says to do”</h1>
<p>I thought I’d gather some of the core ‘things Jeremy says to do’ comments from the video lecture for this part of the lecture.</p>
<ul>
<li>develop your intuition around concepts and code in the notebook, but then once you’ve reached a point where you have something working, copy the code cells above and turn it (minus the comments and markdown) into a function. (<a href="https://youtu.be/Tf-8F5q8Xww?t=4039">link</a>)
<ul>
<li>keep the stuff above it, though, so you can how you reached that final point</li>
</ul></li>
<li>if you’re refactoring your code, make sure that the new / refactored code that you write is giving the same results as the slower / pre-refactoring code. Jeremy uses the <code>test_close</code> function from <code>fastcore.test</code> to do this. (<a href="https://youtu.be/Tf-8F5q8Xww?t=4292">link</a>)</li>
<li>if you’re new to something, experiment with it in a notebook to cement your understanding</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="strickvl/mlops-dot-systems" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>