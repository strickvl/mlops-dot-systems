<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Alex Strick van Linschoten">
<meta name="dcterms.date" content="2025-01-22">
<meta name="description" content="A comprehensive guide to AI system evaluation, synthesising Chapter 4 of Chip Huyen’s ‘AI Engineering.’ These notes detail practical frameworks for assessing AI models, covering evaluation criteria, model selection strategies, and pipeline implementation, while maintaining a balanced perspective between academic rigour and real-world application needs.">

<title>Notes on ‘AI Engineering’ (Chip Huyen) chapter 4 – Alex Strick van Linschoten</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script defer="" data-domain="alexstrick.com" src="https://plausible.io/js/script.js"></script>


<link rel="stylesheet" href="../styles.css">
<link rel="stylesheet" href="../styles/technical.css">
<meta property="og:title" content="Notes on ‘AI Engineering’ (Chip Huyen) chapter 4 – Alex Strick van Linschoten">
<meta property="og:description" content="A comprehensive guide to AI system evaluation, synthesising Chapter 4 of Chip Huyen’s ‘AI Engineering.’ These notes detail practical frameworks for assessing AI models, covering evaluation criteria, model selection strategies, and pipeline implementation, while maintaining a balanced perspective between academic rigour and real-world application needs.">
<meta property="og:image" content="https://alexstrick.com/posts/images/chip-ch4.png">
<meta property="og:site_name" content="Alex Strick van Linschoten">
<meta property="og:image:height" content="812">
<meta property="og:image:width" content="1372">
<meta name="twitter:title" content="Notes on ‘AI Engineering’ (Chip Huyen) chapter 4 – Alex Strick van Linschoten">
<meta name="twitter:description" content="A comprehensive guide to AI system evaluation, synthesising Chapter 4 of Chip Huyen’s ‘AI Engineering.’ These notes detail practical frameworks for assessing AI models, covering evaluation criteria, model selection strategies, and pipeline implementation, while maintaining a balanced perspective between academic rigour and real-world application needs.">
<meta name="twitter:image" content="https://alexstrick.com/posts/images/chip-ch4.png">
<meta name="twitter:creator" content="@strickvl">
<meta name="twitter:image-height" content="812">
<meta name="twitter:image-width" content="1372">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed technical-page quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Alex Strick van Linschoten</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../technical.html"> 
<span class="menu-text">Technical</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../personal.html"> 
<span class="menu-text">Personal</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../all.html"> 
<span class="menu-text">All</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../til.html"> 
<span class="menu-text">TIL</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/strickvl"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://sigmoid.social/web/@alexstrick"> <i class="bi bi-mastodon" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/strickvl"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-rss" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">RSS</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-rss">    
        <li>
    <a class="dropdown-item" href="../technical.xml">
 <span class="dropdown-text">Technical RSS</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../personal.xml">
 <span class="dropdown-text">Personal RSS</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-and-context" id="toc-introduction-and-context" class="nav-link active" data-scroll-target="#introduction-and-context">Introduction and Context</a></li>
  <li><a href="#part-1-evaluation-criteria---a-deep-dive" id="toc-part-1-evaluation-criteria---a-deep-dive" class="nav-link" data-scroll-target="#part-1-evaluation-criteria---a-deep-dive">Part 1: Evaluation Criteria - A Deep Dive</a>
  <ul class="collapse">
  <li><a href="#the-evolution-of-evaluation-driven-development" id="toc-the-evolution-of-evaluation-driven-development" class="nav-link" data-scroll-target="#the-evolution-of-evaluation-driven-development">The Evolution of Evaluation-Driven Development</a></li>
  <li><a href="#the-four-pillars-of-evaluation" id="toc-the-four-pillars-of-evaluation" class="nav-link" data-scroll-target="#the-four-pillars-of-evaluation">The Four Pillars of Evaluation</a></li>
  </ul></li>
  <li><a href="#part-2-model-selection---a-strategic-approach" id="toc-part-2-model-selection---a-strategic-approach" class="nav-link" data-scroll-target="#part-2-model-selection---a-strategic-approach">Part 2: Model Selection - A Strategic Approach</a>
  <ul class="collapse">
  <li><a href="#the-four-step-evaluation-workflow" id="toc-the-four-step-evaluation-workflow" class="nav-link" data-scroll-target="#the-four-step-evaluation-workflow">The Four-Step Evaluation Workflow</a></li>
  <li><a href="#the-build-vs.-buy-decision-matrix" id="toc-the-build-vs.-buy-decision-matrix" class="nav-link" data-scroll-target="#the-build-vs.-buy-decision-matrix">The Build vs.&nbsp;Buy Decision Matrix</a></li>
  </ul></li>
  <li><a href="#part-3-building-evaluation-pipelines---practical-implementation" id="toc-part-3-building-evaluation-pipelines---practical-implementation" class="nav-link" data-scroll-target="#part-3-building-evaluation-pipelines---practical-implementation">Part 3: Building Evaluation Pipelines - Practical Implementation</a>
  <ul class="collapse">
  <li><a href="#system-component-evaluation" id="toc-system-component-evaluation" class="nav-link" data-scroll-target="#system-component-evaluation">System Component Evaluation</a></li>
  <li><a href="#creating-effective-evaluation-guidelines" id="toc-creating-effective-evaluation-guidelines" class="nav-link" data-scroll-target="#creating-effective-evaluation-guidelines">Creating Effective Evaluation Guidelines</a></li>
  <li><a href="#data-management-and-sampling" id="toc-data-management-and-sampling" class="nav-link" data-scroll-target="#data-management-and-sampling">Data Management and Sampling</a></li>
  <li><a href="#meta-evaluation-evaluating-your-evaluation" id="toc-meta-evaluation-evaluating-your-evaluation" class="nav-link" data-scroll-target="#meta-evaluation-evaluating-your-evaluation">Meta-Evaluation: Evaluating Your Evaluation</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Notes on ‘AI Engineering’ (Chip Huyen) chapter 4</h1>
  <div class="quarto-categories">
    <div class="quarto-category">books-i-read</div>
    <div class="quarto-category">llm</div>
    <div class="quarto-category">llms</div>
    <div class="quarto-category">evaluation</div>
  </div>
  </div>

<div>
  <div class="description">
    A comprehensive guide to AI system evaluation, synthesising Chapter 4 of Chip Huyen’s ‘AI Engineering.’ These notes detail practical frameworks for assessing AI models, covering evaluation criteria, model selection strategies, and pipeline implementation, while maintaining a balanced perspective between academic rigour and real-world application needs.
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Alex Strick van Linschoten </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 22, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>This chapter represents a crucial bridge between academic research and production engineering practice in AI system evaluation. What sets it apart is the Chip’s very balanced perspective - neither succumbing to the prevalent hype in the field nor becoming overly academic. Instead, she melds together practical insights with theoretical foundations, creating a useful framework for evaluation that acknowledges both technical and ethical considerations.</p>
<section id="introduction-and-context" class="level2">
<h2 class="anchored" data-anchor-id="introduction-and-context">Introduction and Context</h2>
<blockquote class="blockquote">
<p><strong>Key Insight</strong>: The author’s approach demonstrates that effective AI system evaluation requires a synthesis of academic rigour and practical engineering concerns, much like how traditional software engineering evolved to balance theoretical computer science with practical development methodologies.</p>
</blockquote>
<p>The chapter is structured in three main parts, each building upon the previous to create a complete picture of AI system evaluation:</p>
<ol type="1">
<li>Evaluation criteria fundamentals</li>
<li>Model selection and benchmark navigation</li>
<li>Practical pipeline implementation</li>
</ol>
</section>
<section id="part-1-evaluation-criteria---a-deep-dive" class="level2">
<h2 class="anchored" data-anchor-id="part-1-evaluation-criteria---a-deep-dive">Part 1: Evaluation Criteria - A Deep Dive</h2>
<section id="the-evolution-of-evaluation-driven-development" class="level3">
<h3 class="anchored" data-anchor-id="the-evolution-of-evaluation-driven-development">The Evolution of Evaluation-Driven Development</h3>
<p>The author introduces <strong>evaluation-driven development</strong> (EDD), a methodological evolution that adapts the principles of test-driven development to the unique challenges of AI systems.</p>
<blockquote class="blockquote">
<p><strong>Evaluation-Driven Development</strong>: A methodology where AI application development begins with explicit evaluation criteria, similar to how test-driven development starts with test cases. However, EDD encompasses a broader range of metrics and considerations specific to AI systems.</p>
</blockquote>
<p>The fundamental principle here is that AI applications require a more nuanced and multifaceted approach to evaluation than traditional software. Where traditional software might have binary pass/fail criteria, AI systems often operate in a spectrum of performance across multiple dimensions.</p>
</section>
<section id="the-four-pillars-of-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="the-four-pillars-of-evaluation">The Four Pillars of Evaluation</h3>
<section id="domain-specific-capability" class="level4">
<h4 class="anchored" data-anchor-id="domain-specific-capability">1. Domain-Specific Capability</h4>
<p>The author presents domain-specific capability evaluation as the foundational layer of AI system assessment. This approach is particularly innovative in its use of <strong>multiple choice evaluation techniques</strong> - a method that bridges the gap between human-interpretable results and machine performance metrics.</p>
<p><em>For example</em>, when evaluating code generation capabilities, presenting a model with multiple implementations where only one is functionally correct serves as both a test and a teaching tool. This mimics how human experts often evaluate junior developers’ understanding of coding patterns and best practices.</p>
</section>
<section id="generation-capability" class="level4">
<h4 class="anchored" data-anchor-id="generation-capability">2. Generation Capability</h4>
<p>The section on generation capability draws parallels with the historical development of Natural Language Generation (NLG) in computational linguistics. This historical context provides valuable insights into how we can approach modern language model evaluation.</p>
<p>The author breaks down factual consistency into two crucial dimensions:</p>
<blockquote class="blockquote">
<p><strong>Local Factual Consistency</strong>: The internal coherence of generated content and its alignment with the immediate context of the prompt. This is analogous to maintaining logical consistency within a single conversation or document.</p>
<p><strong>Global Factual Consistency</strong>: The accuracy of generated content when compared against established knowledge and facts. This represents the model’s ability to maintain truthfulness in a broader context.</p>
</blockquote>
<p>The discussion of hallucination detection is particularly noteworthy, presenting three complementary approaches:</p>
<ol type="1">
<li><strong>Basic Prompting</strong>: Direct detection through carefully crafted prompts</li>
<li><strong>Self-Verification</strong>: A novel approach using internal consistency checks across multiple generations</li>
<li><strong>Knowledge-Augmented Verification</strong>: Advanced techniques like Google DeepMind’s SAFE paper (search augmented factuality evaluator)</li>
</ol>
<p>The knowledge-augmented verification system represents a fascinating approach to fact-checking that mirrors how human experts verify information:</p>
<ul>
<li>It breaks down complex statements into atomic claims</li>
<li>Each claim is independently verified through search</li>
<li>The results are synthesised into a final accuracy assessment</li>
</ul>
<p>Seems pricey, though :)</p>
</section>
<section id="instruction-following-capability" class="level4">
<h4 class="anchored" data-anchor-id="instruction-following-capability">3. Instruction Following Capability</h4>
<p>The author makes a crucial observation about the bidirectional nature of instruction following evaluation. Poor performance might indicate either model limitations or instruction ambiguity - a distinction that’s often overlooked in practice.</p>
<blockquote class="blockquote">
<p><strong>Instruction-Performance Paradox</strong>: The quality of instruction following cannot be evaluated in isolation from the quality of the instructions themselves, creating a circular dependency that must be carefully managed in evaluation design.</p>
</blockquote>
<p>The solution proposed is the development of custom benchmarks that specifically target your application’s requirements. This approach ensures that your evaluation criteria align perfectly with your practical needs rather than relying solely on generic benchmarks.</p>
</section>
<section id="cost-and-latency-considerations" class="level4">
<h4 class="anchored" data-anchor-id="cost-and-latency-considerations">4. Cost and Latency Considerations</h4>
<p>The author introduces the concept of <strong>Pareto optimization</strong> in the context of AI system evaluation, demonstrating how different performance metrics often involve trade-offs that must be carefully balanced.</p>
<blockquote class="blockquote">
<p><strong>Pareto Optimization</strong>: A multi-objective optimization approach where improvements in one metric cannot be achieved without degrading another, leading to a set of optimal trade-off solutions rather than a single optimal point.</p>
</blockquote>
</section>
</section>
</section>
<section id="part-2-model-selection---a-strategic-approach" class="level2">
<h2 class="anchored" data-anchor-id="part-2-model-selection---a-strategic-approach">Part 2: Model Selection - A Strategic Approach</h2>
<section id="the-four-step-evaluation-workflow" class="level3">
<h3 class="anchored" data-anchor-id="the-four-step-evaluation-workflow">The Four-Step Evaluation Workflow</h3>
<p>The author presents a sophisticated workflow that combines both quantitative and qualitative factors in model selection. This approach is particularly valuable because it acknowledges the complexity of real-world deployment while providing a structured path forward.</p>
<ol type="1">
<li><p><strong>Initial Filtering</strong> The first step involves filtering based on hard constraints, which might include:</p>
<ul>
<li>Deployment requirements (on-premise vs.&nbsp;cloud)</li>
<li>Security and privacy considerations</li>
<li>Licensing restrictions</li>
<li>Resource constraints</li>
</ul></li>
<li><p><strong>Public Information Assessment</strong> This stage involves a systematic review of:</p>
<ul>
<li>Benchmark performances across relevant tasks</li>
<li>Leaderboard rankings with context</li>
<li>Published latency and cost metrics</li>
</ul>
<p>The author emphasises the importance of looking beyond raw numbers to understand the context and limitations of public benchmarks.</p></li>
<li><p><strong>Experimental Evaluation</strong> This phase involves hands-on testing with your specific use case, considering:</p>
<ul>
<li>Custom evaluation metrics</li>
<li>Integration requirements</li>
<li>Real-world performance characteristics</li>
</ul></li>
<li><p><strong>Continuous Monitoring</strong> The final step acknowledges that evaluation is an ongoing process, not a one-time event. This involves:</p>
<ul>
<li>Regular performance monitoring</li>
<li>Failure detection and analysis</li>
<li>Feedback collection and incorporation</li>
<li>Continuous improvement cycles</li>
</ul></li>
</ol>
</section>
<section id="the-build-vs.-buy-decision-matrix" class="level3">
<h3 class="anchored" data-anchor-id="the-build-vs.-buy-decision-matrix">The Build vs.&nbsp;Buy Decision Matrix</h3>
<p>The author provides an analysis of the build vs.&nbsp;buy decision, going beyond simple cost comparisons to consider factors like:</p>
<blockquote class="blockquote">
<p><strong>Total Cost of Ownership (TCO)</strong>: The complete cost picture including: - Direct costs (API fees, computing resources) - Indirect costs (engineering time, maintenance) - Opportunity costs (time to market, feature development) - Risk costs (security, reliability, vendor lock-in)</p>
</blockquote>
<p>This section particularly shines in its discussion of the often-overlooked aspects of model deployment, such as the hidden costs of maintaining self-hosted models and the true value of vendor-provided updates and improvements.</p>
</section>
</section>
<section id="part-3-building-evaluation-pipelines---practical-implementation" class="level2">
<h2 class="anchored" data-anchor-id="part-3-building-evaluation-pipelines---practical-implementation">Part 3: Building Evaluation Pipelines - Practical Implementation</h2>
<section id="system-component-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="system-component-evaluation">System Component Evaluation</h3>
<p>The author advocates for a <strong>dual-track evaluation approach</strong>:</p>
<ol type="1">
<li>End-to-end system evaluation</li>
<li>Component-level assessment</li>
</ol>
<p>This approach allows organisations to:</p>
<ul>
<li>Identify bottlenecks and failure points</li>
<li>Understand component interactions</li>
<li>Make targeted improvements</li>
<li>Maintain system reliability during updates</li>
</ul>
</section>
<section id="creating-effective-evaluation-guidelines" class="level3">
<h3 class="anchored" data-anchor-id="creating-effective-evaluation-guidelines">Creating Effective Evaluation Guidelines</h3>
<p>The author emphasises the importance of creating clear, actionable evaluation guidelines that bridge technical and business metrics. This section introduces the concept of <strong>metric alignment</strong> - ensuring that technical evaluation metrics directly correspond to business value.</p>
<blockquote class="blockquote">
<p><strong>Metric Alignment</strong>: The process of mapping technical performance metrics to business outcomes, creating a clear connection between model improvements and business value.</p>
</blockquote>
</section>
<section id="data-management-and-sampling" class="level3">
<h3 class="anchored" data-anchor-id="data-management-and-sampling">Data Management and Sampling</h3>
<p>Chip provides valuable insights into data management for evaluation, including:</p>
<blockquote class="blockquote">
<p><strong>Data Slicing</strong>: The strategic separation of evaluation data into meaningful subsets to: - Identify performance variations across different use cases - Detect potential biases - Enable targeted improvement efforts - Avoid Simpson’s paradox in performance analysis</p>
</blockquote>
<p>The discussion of sample size is particularly practical, providing concrete guidelines based on statistical confidence levels and desired detection thresholds. The author cites OpenAI’s research suggesting that sample sizes between 100 and 1,000 are typically sufficient for most evaluation needs, depending on the required confidence level.</p>
<p><img src="images/chip4-sample-number.png" class="img-fluid"></p>
</section>
<section id="meta-evaluation-evaluating-your-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="meta-evaluation-evaluating-your-evaluation">Meta-Evaluation: Evaluating Your Evaluation</h3>
<p>The chapter concludes with a crucial discussion of meta-evaluation - the process of assessing and improving your evaluation pipeline itself. This includes considerations of:</p>
<ul>
<li>Signal quality and reliability</li>
<li>Metric correlation and redundancy</li>
<li>Resource utilisation and efficiency</li>
<li>Integration with development workflows</li>
</ul>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The author concludes around the inherent limitations of AI system evaluation: no single metric or method can fully capture the complexity of these systems. However, this acknowledgment leads to a constructive approach: combining multiple evaluation methods, maintaining awareness of their limitations, and continuously iterating based on real-world feedback.</p>
<p>This chapter ultimately provides a solid framework for AI system evaluation that is both theoretically sound and practically applicable. It serves as a valuable resource for organisations working to implement effective evaluation strategies for their AI systems, while maintaining a clear-eyed view of both the possibilities and limitations of current evaluation methods.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/alexstrick\.com");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<script src="https://utteranc.es/client.js" repo="strickvl/mlops-dot-systems" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->




</body></html>