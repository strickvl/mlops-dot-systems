{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6cbc759a",
   "metadata": {},
   "source": [
    "---\n",
    "aliases:\n",
    "- /computervision/fastai/parttwo/2022/10/24/foundations-mnist-basics.html\n",
    "date: '2022-10-24'\n",
    "description: \"Notes and some personal exploration following through the lesson 10 course materials from FastAI part 2. We cover the basics of loading in our data and generating our matrix.\"\n",
    "output-file: 2022-10-24-foundations-mnist-basics.html\n",
    "title: 'From the foundation up: Fashion-MNIST basics from Lesson 10'\n",
    "image: images/fashion-mnist-part-2/fashion-mnist-cover.png\n",
    "author: Alex Strick van Linschoten\n",
    "categories: [computervision, fastai, parttwo]\n",
    "toc: true\n",
    "comments:\n",
    "    utterances:\n",
    "        repo: strickvl/mlops-dot-systems\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13102e0c-9b4f-4aa3-ad6a-68bd8b4c31c1",
   "metadata": {},
   "source": [
    "In lesson 10 of the FastAI course, we began by examining some new research that had just been released ([the iMagic paper](https://arxiv.org/abs/2210.09276)) along with one of the key insights ('progressive distillation') of the paper. I'll maybe return to that in a separate blogpost but I wanted to focus on the second half of the lesson where we start the work of actually building up our library of tools to replicate all the pieces of Stable Diffusion.\n",
    "\n",
    "To make things more complicated, we're allowed to use only a basic set of building blocks (at least in the first iteration) so as to really understand how things are working. This includes:\n",
    "\n",
    "- Python\n",
    "- The Python standard library\n",
    "- matplotlib\n",
    "- Jupyter notebooks and nbdev\n",
    "\n",
    "This notebook will showcase some of my experimentation and learnings around the things we went through in this lesson. I've also compiled a table showing the various pieces we got to in the lesson, pairing the specific task we were trying to do along with the associated skill or part of the Python standard library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041b6ead-93f8-4256-84d0-f0c0fcf32ee5",
   "metadata": {},
   "source": [
    "|   | Task                                    | Skill / Library               | Docs link                                                                                                                                  |\n",
    "| - | --------------------------------------- | ----------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| 1 | **Download Fashion MNIST**              | urllib.requests.urlretrieve   | [link](https://docs.python.org/3/library/urllib.request.html#urllib.request.urlretrieve)                                                   |\n",
    "| 2 | **Unzip & separate out the parts**      | gzip                          | [link](https://docs.python.org/3/library/gzip.html)                                                                                        |\n",
    "|   |                                         | pickle                        | [link](https://docs.python.org/3/library/pickle.html)                                                                                      |\n",
    "|   |                                         | destructuring                 |                                                                                                                                            |\n",
    "| 3 | **Turn the list into a matrix**         | chunking into a list of lists |                                                                                                                                            |\n",
    "|   |                                         | yield / next (generators)     | [link](https://docs.python.org/3/reference/expressions.html#yieldexpr)                                                                     |\n",
    "| 4 | **Plot out the image using matplotlib** | matplotlib                    | [link](https://matplotlib.org)                                                                                                             |\n",
    "| 5 | **Define a matrix class**               | `__init__`                      | [link](https://docs.python.org/3/reference/datamodel.html?highlight=init#object.__init__)                                                  |\n",
    "|   |                                         | `__getitem__`                   | [link](https://docs.python.org/3/reference/datamodel.html?highlight=init#object.__getitem__)                                               |\n",
    "| 6 | **Access tensor values**                | Pytorch Tensor                | [link](https://pytorch.org/docs/stable/tensors.html)                                                                                       |\n",
    "|   |                                         | map                           | [link](https://docs.python.org/3/library/functions.html#map)                                                                               |\n",
    "|   |                                         | tensor().reshape()            | [link](https://pytorch.org/docs/stable/generated/torch.Tensor.reshape.html#torch.Tensor.reshape)                                           |\n",
    "| 7 | **Find the shape, min and max values**  | tensor().shape                |                                                                                                                                            |\n",
    "|   |                                         | tensor().min()                | [link](https://pytorch.org/docs/stable/generated/torch.min.html#torch.min)                                                                 |\n",
    "|   |                                         | tensor().max()                | [link](https://pytorch.org/docs/stable/generated/torch.max.html#torch.max)                                                                 |\n",
    "| 8 | **Generate some random numbers**        | random.random                 | [link](https://docs.python.org/3/library/random.html#random.random)                                                                        |\n",
    "| 9 | **Profile your code**                   | %timeit                       | [link1](https://docs.python.org/3/library/timeit.html) / [link2](https://ipython.org/ipython-doc/dev/interactive/magics.html#magic-timeit) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb116ab3-228b-4c7b-ad76-a1cb35fdd8d7",
   "metadata": {},
   "source": [
    "At the bottom of the post, I'll also include my collation of the \"Things Jeremy says to do\" which has [a bit of a precedent on the fastai forums](https://forums.fast.ai/t/podcast-writeup-summaries-things-jeremy-says-to-do-qs/66194) so I thought I'd share them as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc29c31-711e-4e62-a5d2-d8ec033e47bf",
   "metadata": {},
   "source": [
    "# Downloading MNIST\n",
    "\n",
    "We start by downloading our dataset. I'm going to replicate the work we do in class while using Zalando's alternative version of MNIST, entitled [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist). I previously used it on this blog ([here](https://mlops.systems/fastai/computervision/pytorch/2022/05/11/fashion-mnist-pixel-similarity.html), for example, but also elsewhere) while working through part 1 of the course, albeit at a much higher level using PyTorch to do similar things that we'll be doing this time round. It's comparable but also different, so I'm looking forward to working through whatever challenges are raised.\n",
    "\n",
    "The URLs are specified [on the Github Repo](https://github.com/zalandoresearch/fashion-mnist), so I'll include those as constants here first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82cd81a-d1bb-4948-8780-89444e1f38ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/\"\n",
    "\n",
    "TRAINING_IMAGES = BASE_URL + \"train-images-idx3-ubyte.gz\"\n",
    "TRAINING_IMAGES_LABELS = BASE_URL + \"train-labels-idx1-ubyte.gz\"\n",
    "TEST_IMAGES = BASE_URL + \"t10k-images-idx3-ubyte.gz\"\n",
    "TEST_IMAGES_LABELS = BASE_URL + \"t10k-labels-idx1-ubyte.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d0618-fab8-4720-9f31-2741fe047cb6",
   "metadata": {},
   "source": [
    "We now want a place where we can save them, so we'll use `pathlib` to create a `data` directory in our current working directory, but only if it doesn't already exist. We also set up the final locations of the data for when we download it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76860c2-f696-42e4-af31-06b46b96a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create local path directory if it doesn't exist\n",
    "from pathlib import Path\n",
    "\n",
    "LOCAL_PATH = Path(\"data\")\n",
    "# check whether the path exists; create it if it doesn't exist\n",
    "if not LOCAL_PATH.exists():\n",
    "    LOCAL_PATH.mkdir(exist_ok=True)\n",
    "    \n",
    "training_images_path = LOCAL_PATH / \"train-images-idx3-ubyte.gz\"\n",
    "training_images_labels_path = LOCAL_PATH / \"train-labels-idx1-ubyte.gz\"\n",
    "test_images_path = LOCAL_PATH / \"t10k-images-idx3-ubyte.gz\"\n",
    "test_images_labels_path = LOCAL_PATH / \"t10k-labels-idx1-ubyte.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42845a5f-2efe-4ac1-9712-a27dc55d245e",
   "metadata": {},
   "source": [
    "There's probably a more elegant way to do this where we loop over a list, but the way I set up the URLs and the filenames didn't lend itself to that approach so here I just download them one by one, but only if they don't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07b3a800-679d-48f4-b373-a3b4bc091e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the raw data if it doesn't exist\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "if not training_images_path.exists():\n",
    "    urlretrieve(TRAINING_IMAGES, training_images_path)\n",
    "if not training_images_labels_path.exists():\n",
    "    urlretrieve(TRAINING_IMAGES_LABELS, training_images_labels_path)\n",
    "if not test_images_path.exists():\n",
    "    urlretrieve(TEST_IMAGES, test_images_path)\n",
    "if not test_images_labels_path.exists():\n",
    "    urlretrieve(TEST_IMAGES_LABELS, test_images_labels_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0df0211-cc5f-4f80-bb70-ee7251ab7f88",
   "metadata": {},
   "source": [
    "Here you can see that we have downloaded four files as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51feeb08-d343-4568-b32f-b8d2b36ff060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 60328\n",
      "-rw-r--r--  1 strickvl  staff   4422102 22 Oct 16:12 t10k-images-idx3-ubyte.gz\n",
      "-rw-r--r--  1 strickvl  staff      5148 22 Oct 16:12 t10k-labels-idx1-ubyte.gz\n",
      "-rw-r--r--  1 strickvl  staff  26421880 22 Oct 16:12 train-images-idx3-ubyte.gz\n",
      "-rw-r--r--  1 strickvl  staff     29515 22 Oct 16:12 train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -l data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef63a6c-179d-4276-a8e4-c591e43651f1",
   "metadata": {},
   "source": [
    "# Unzip the files and separate out the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12a189-fe4d-4a64-af74-b2ad4ac89a84",
   "metadata": {},
   "source": [
    "In the lesson, Jeremy downloads a pre-made MNIST file which contains a tuple of tuples. With Fashion-MNIST, we have four separate files representing our training and test data and our labels for each. Now our task is to unzip those files and grab the data as arrays.\n",
    "\n",
    "Note that there are convenience functions provided for both MNIST and Fashion-MNIST to do much of what we do below, since most people want the data as numpy arrays, not Python arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effee242-521a-4332-a926-ef65e0d4f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant standard library packages\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df520ba6-658e-4a99-b933-b6550732db4d",
   "metadata": {},
   "source": [
    "We have one elephant in the room which is this `parse_idx` function that I'm showing below in a collapsed cell. This was one part that I didn't want to get too lost in so I simply went to the source code of one of these helper functions, [specifically that written by `datapythonista`](https://github.com/datapythonista/mnist/blob/master/mnist/__init__.py) for MNIST.\n",
    "\n",
    "This still all is standard library imports so I think technically I'm ok including this code here since the MNIST download Jeremy used in the lesson comes pre-parsed, it seems. After inspecting the data in the files, it seems that we have a series of bytes that need to be parsed somehow if they're going to be used as an array. The original function returned a numpy array, but I modified it slightly such that it returns a nested array instead. I consider this not a very interesting part of the process so I'm hiding it away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee3dfefc-0bef-4de8-bc82-d4529de78842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "# taken from https://github.com/datapythonista/mnist/blob/master/mnist/__init__.py\n",
    "import os\n",
    "import functools\n",
    "import operator\n",
    "import struct\n",
    "import array\n",
    "import tempfile\n",
    "\n",
    "def parse_idx(fd):\n",
    "    \"\"\"Parse an IDX file, and return it as an array of arrays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fd : file\n",
    "        File descriptor of the IDX file to parse\n",
    "    endian : str\n",
    "        Byte order of the IDX file. See [1] for available options\n",
    "    Returns\n",
    "    -------\n",
    "    data : array\n",
    "        Numpy array with the dimensions and the data in the IDX file\n",
    "    1. https://docs.python.org/3/library/struct.html\n",
    "        #byte-order-size-and-alignment\n",
    "    \"\"\"\n",
    "    DATA_TYPES = {0x08: 'B',  # unsigned byte\n",
    "                  0x09: 'b',  # signed byte\n",
    "                  0x0b: 'h',  # short (2 bytes)\n",
    "                  0x0c: 'i',  # int (4 bytes)\n",
    "                  0x0d: 'f',  # float (4 bytes)\n",
    "                  0x0e: 'd'}  # double (8 bytes)\n",
    "\n",
    "    header = fd.read(4)\n",
    "    if len(header) != 4:\n",
    "        raise IdxDecodeError('Invalid IDX file, '\n",
    "                             'file empty or does not contain a full header.')\n",
    "\n",
    "    zeros, data_type, num_dimensions = struct.unpack('>HBB', header)\n",
    "\n",
    "    if zeros != 0:\n",
    "        raise IdxDecodeError('Invalid IDX file, '\n",
    "                             'file must start with two zero bytes. '\n",
    "                             'Found 0x%02x' % zeros)\n",
    "\n",
    "    try:\n",
    "        data_type = DATA_TYPES[data_type]\n",
    "    except KeyError:\n",
    "        raise IdxDecodeError('Unknown data type '\n",
    "                             '0x%02x in IDX file' % data_type)\n",
    "\n",
    "    dimension_sizes = struct.unpack('>' + 'I' * num_dimensions,\n",
    "                                    fd.read(4 * num_dimensions))\n",
    "\n",
    "    data = array.array(data_type, fd.read())\n",
    "    data.byteswap()  # looks like array.array reads data as little endian\n",
    "\n",
    "    expected_items = functools.reduce(operator.mul, dimension_sizes)\n",
    "    if len(data) != expected_items:\n",
    "        raise IdxDecodeError('IDX file has wrong number of items. '\n",
    "                             'Expected: %d. Found: %d' % (expected_items,\n",
    "                                                          len(data)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb1b3a8-aec1-4f2f-a6ac-aef95ec4d0f8",
   "metadata": {},
   "source": [
    "There's one final piece of the process which comes from the fact that the array (i.e. the `data` local variable inside the `parse_idx` function) that gets returned is a single array (i.e. all the pixel values for all 60,000 images just listed one after another). We'll want to split these up into separate chunks:\n",
    "\n",
    "- splitting each image into a separate array of 784 values (because our images are 28x28 size)\n",
    "- then splitting each image into an array of arrays giving us our 28x28 matrix.\n",
    "\n",
    "I'll include the code that we use for this in the class, a `chunks` function, but I'll return to how it works once everything is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ec2e51-0a22-4e3d-887a-c56d1866680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk things together\n",
    "def chunks(x, size):\n",
    "    for i in range(0, len(x), size): \n",
    "        yield x[i:i + size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0184a08c-9a78-4bd1-82c1-1439da6be92c",
   "metadata": {},
   "source": [
    "# Load the data into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c548b5e-9ab9-4bac-b585-55a7f41df984",
   "metadata": {},
   "source": [
    "We use the chunks function here to turn our array of 47,040,000 values into matrices. To start with, something like `x_train` will have 60,000 separate arrays of 784 pixels, as we can see when we get the lengths of the initial array and then the length of the first item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb9c5eb0-9998-470e-9f00-52f47eea7553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the files and extract the images \n",
    "with gzip.open(training_images_path, 'rb') as f:\n",
    "    pixels = list(parse_idx(f))\n",
    "    x_train = list(chunks(pixels, 784))\n",
    "\n",
    "with gzip.open(training_images_labels_path, 'rb') as f:\n",
    "    y_train = list(parse_idx(f))\n",
    "    \n",
    "with gzip.open(test_images_path, 'rb') as f:\n",
    "    pixels = list(parse_idx(f))\n",
    "    x_valid = list(chunks(pixels, 784))\n",
    "    \n",
    "with gzip.open(test_images_labels_path, 'rb') as f:\n",
    "    y_valid = list(parse_idx(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21c9fd44-4d21-450f-a6e0-d175ae73fe2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa85dd-6dc5-40f5-8744-346603435213",
   "metadata": {},
   "source": [
    "The labels are in a slightly different format, containing single integer values indicating which item the image refers to. We can check and show that we have 60,000 of those values, as we'd expect, and we can even see what values those refer to with a simple conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79421b1f-8c15-4e55-9661-28583dfc0e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aee4da79-cf9e-4de3-8868-819f7ba71356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 0, 0, 3, 0, 2, 7, 2, 5, 5]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06f27a5c-e4ae-4829-aec5-aeffb7e735a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ankle boot',\n",
       " 'T-shirt/top',\n",
       " 'T-shirt/top',\n",
       " 'Dress',\n",
       " 'T-shirt/top',\n",
       " 'Pullover',\n",
       " 'Sneaker',\n",
       " 'Pullover',\n",
       " 'Sandal',\n",
       " 'Sandal']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this list is taken from the README of the Fashion-MNIST repository\n",
    "# https://github.com/zalandoresearch/fashion-mnist\n",
    "index_to_label = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}\n",
    "\n",
    "list(map(lambda x: index_to_label[x], y_train[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1864f180-c4dc-489c-925c-6479511d3cb5",
   "metadata": {},
   "source": [
    "# Plot some examples using `matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35dc609-7da3-4a20-ad1d-5f3bdfaa9b41",
   "metadata": {},
   "source": [
    "We can plot out one or two of our images to confirm that we're seeing the right images and that everything's as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d063f569-dd3b-48c5-bf3a-f1d4a954acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fac8665-f925-450a-8f76-92f4ec0eee2d",
   "metadata": {},
   "source": [
    "This is the first image, which should be an ankle boot as per the labels above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e00b6ed6-b40b-4280-8fa4-92c0bac6a0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "plt.imshow(list(chunks(x_train[0], 28)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd4262-647c-4f6b-a149-9ce28527314d",
   "metadata": {},
   "source": [
    "This is the fourth image, which should be a dress as per the labels above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99861b6c-2ee7-41c6-832e-a9e96c0bf632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "plt.imshow(list(chunks(x_train[3], 28)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629422ac-4d77-4a01-b6fc-f84dd27a1a08",
   "metadata": {},
   "source": [
    "Everything looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c85d907-ebb6-4a51-b248-eb7c9b9a8fa9",
   "metadata": {},
   "source": [
    "# Chunking with iterators and generators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3c31e1-0f66-4373-8b86-e20cb955883b",
   "metadata": {},
   "source": [
    "I promised I'd return to the `chunks` function defined above. There's a way to define it in a simpler fashion without using generators that goes something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebeefa25-bb98-4708-ab98-a0ef022873b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(x, size):\n",
    "    result = []\n",
    "    for i in range(0, len(x), size):\n",
    "        subarray = x[i:i + size]\n",
    "        result.append(subarray)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e92c734-8040-4edb-be08-390d72ac5d4d",
   "metadata": {},
   "source": [
    "Functionally this does almost the same thing as what we have above, but this simpler version is less ideal because we're iteratively building up our array in memory on the fly.\n",
    "\n",
    "The advantage of using a generator (which we create when we use `yield`) is that it only grabs the number of items we need at once, so it's far more memory efficient. (In other words, instead of grabbing all 60,000 images at once, we only make one image (i.e. 784 items / pixels) available at any one time.) With our generator, we can see the next set of items by calling `next` until we reach a `StopIterationError`.\n",
    "\n",
    "In our implementation, we don't get so many of those benefits since we're still going to store everything in memory anyway. We wrap all our chunk generator functions in `list()` which causes the interpreter to unfurl or unwrap our chunks into an array of arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ef4ef-6b75-4065-a939-34287b6bb00c",
   "metadata": {},
   "source": [
    "# Define a matrix class\n",
    "\n",
    "In standard Python if we want to index into one of our array image we'd normally have to do something like `image[0][15]` whereas in machine learning we generally prefer to do something like `image[0, 15]`. So our next step in manually implementing these things would be to create a `Matrix` class that allows us to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e99521e-b7dc-4735-a36a-f8c9e9f60943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matrix:\n",
    "    def __init__(self, vals):\n",
    "        self.vals = vals\n",
    "        \n",
    "    def __getitem__(self, vals):\n",
    "        return self.vals[vals[0]][vals[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85ada86e-10de-4431-980f-4a35514e035b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 175)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = list(chunks(x_train[3], 28))\n",
    "Matrix(img)[0, 10], img[0][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d66906f-e439-4bf3-9ca2-2255acfd7de2",
   "metadata": {},
   "source": [
    "Now we have a function that does what we want. You can see we used the built-in `__getitem__` function which we over-wrote. This is what Python uses under the hood when you use square brackets to get values from an array, so by overwriting it we can achieve the behaviour we're looking for.\n",
    "\n",
    "In reality, this implementation probably leaves a bit to be desired, so now that we've implemented it from scratch, we can discard our own version and just use a `tensor` object from PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e5a3d04-094d-45d4-a54a-2dfca1c37311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcd25dc6-0141-4a7d-b740-0f5e67f59ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tensor(list(chunks(x_train[3], 28)))\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c987270-8e9d-4506-ae6f-20e90409e7f9",
   "metadata": {},
   "source": [
    "Now that we know it works, we can map all our values and turn them into tensor objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed273f6b-cd20-4e1b-92cf-d92e490a3480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(tensor, (x_train, y_train, x_valid, y_valid))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a317672-fee0-4551-bf5b-708e0ff9995e",
   "metadata": {},
   "source": [
    "As mentioned above, using tensors comes with a bunch of extra benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a1c36-26d9-4887-8dd3-b737348aa183",
   "metadata": {},
   "source": [
    "# Find the shape, min and max values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db58000-1849-44a1-b0d8-3d49a64afa72",
   "metadata": {},
   "source": [
    "Our `x_train` is in the shape [60000, 784] and our y_train is just 60,000 individual values. So we still need to chunk our images into 28x28 matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "865edbc0-c0b9-462f-96ad-0dbf78929414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8018bbe-d7e2-45c1-8043-19a9875b77fd",
   "metadata": {},
   "source": [
    "For the chunking process, instead of our own function we can use PyTorch's `reshape` method. Note that we pass in the desired new shape, so in our case that could be `(60000,28,28)`. It is more common, however, to use and see the number -1 for the first value, which implies that PyTorch should figure out what the value for that first dimension should be. In our case, we have 60,000 items so that's how big it should be and these two options are both equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1350d7f-2f69-4aaf-9e67-48ef8b9d4116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_imgs = x_train.reshape((60000,28,28))\n",
    "train_imgs = x_train.reshape((-1,28,28))\n",
    "train_imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3944a1-0b6f-45af-9e7c-d70ae1240878",
   "metadata": {},
   "source": [
    "We can find out the minimum and maximum value found inside one of our images by using Python's `min`, but this is an inbuilt method on the tensor object as well so we can use that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f27331f-81bc-4837-8352-3e47b275e937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(255))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs[0].min(), train_imgs[0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115bc7cb-51a8-48b5-ba91-794dc88fe268",
   "metadata": {},
   "source": [
    "As expected, our pixel values represent the 256 shades of grey available. Our labels represent the 10 possible clothing types listed above, so we'd expect our minimum and maximum to be zero and nine respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c05ed2eb-28e9-46c1-a472-939132a3a02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(9))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d09099-ff03-44ee-a482-2297ffeb06fb",
   "metadata": {},
   "source": [
    "# Generate some random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab5d34-8be1-4ee8-b751-da0015615c34",
   "metadata": {},
   "source": [
    "We finished out the lesson with a brief discussion of random number generators, how to implement them and how this might be important for deep learning work. As we learned, there is no way for computers to generate truly random numbers. People go to interesting lengths to create their own random numbers, such as [the infamous lava lamp wall](https://www.cloudflare.com/en-gb/learning/ssl/lava-lamp-encryption/) at Cloudflare, but we are left with being able to create only pseudo-random numbers.\n",
    "\n",
    "In the class we see a way based on the Wichmann Hill algorithm used before Python 2.3, which goes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b9d05d4-f001-40b6-a662-5368c42f9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_state = None\n",
    "def seed(a):\n",
    "    global rnd_state\n",
    "    a, x = divmod(a, 30268)\n",
    "    a, y = divmod(a, 30306)\n",
    "    a, z = divmod(a, 30322)\n",
    "    rnd_state = int(x)+1, int(y)+1, int(z)+1\n",
    "\n",
    "def rand():\n",
    "    global rnd_state\n",
    "    x, y, z = rnd_state\n",
    "    x = (171 * x) % 30269\n",
    "    y = (172 * y) % 30307\n",
    "    z = (170 * z) % 30323\n",
    "    rnd_state = x,y,z\n",
    "    return (x/30269 + y/30307 + z/30323) % 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f1fe4-e321-4d13-8616-34cdaa5dc8f6",
   "metadata": {},
   "source": [
    "We have two functions. It's important to note that the `seed` is an important part of these pseudo-random number generators. The seed gives us a number that our generator starts with. Note also how we use global state to store the `rnd_state` variable, and how we are continually updating our values in that state as we generate. Also note that the process of generating the values is fairly simple, but also eminently reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2405c24-60e1-4a28-bf20-89458e8dc8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24775, 23862, 14675)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed(2349873456787298) # some number I came up with by mashing my keyboard numbers\n",
    "rnd_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fee9051-997d-4e25-8a4a-6700a11dc6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6580068826155674, 0.669616116835976, 0.9249613879702964)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand(),rand(),rand()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca02f25-b10f-404a-b22c-c20049249af5",
   "metadata": {},
   "source": [
    "We now have a function which generates pseudo-random numbers, but as we'll see, it's not the fastest bit of code around..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d336ad53-a376-4a76-af25-9dfb014a0d5c",
   "metadata": {},
   "source": [
    "# Profile our code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec80fc-104c-4c3c-9308-0e22c7263ba7",
   "metadata": {},
   "source": [
    "Python has a handy [`timeit` module](https://docs.python.org/3/library/timeit.html) which allows you to calculate how long your code takes to run. What's more, it'll run your code hundreds or thousands of times to get average run times. Here we can see how fast our pseudo-random number generator takes to run, on average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fbfdfcf-4290-4bc1-9153-77449dc0e470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.05 ms ± 500 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 list(chunks([rand() for _ in range(7840)], 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb0d4d-2274-48be-a43e-03b49a8c5255",
   "metadata": {},
   "source": [
    "If we compare it against PyTorch's random number generator, we can see a distinct difference, however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cbcd8ae-7670-42cb-9375-7ff007e724a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.1 µs ± 23.5 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 torch.randn(784,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6333c-4276-4975-8196-6d696096ff82",
   "metadata": {},
   "source": [
    "Now we're talking about microseconds vs miliseconds, which is a big difference, so we should probably stick to how PyTorch does it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97c5d5ac-597f-4e9f-a8f1-a66e43caae81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "randn(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
       "\n",
       "Returns a tensor filled with random numbers from a normal distribution\n",
       "with mean `0` and variance `1` (also called the standard normal\n",
       "distribution).\n",
       "\n",
       ".. math::\n",
       "    \\text{out}_{i} \\sim \\mathcal{N}(0, 1)\n",
       "\n",
       "The shape of the tensor is defined by the variable argument :attr:`size`.\n",
       "\n",
       "Args:\n",
       "    size (int...): a sequence of integers defining the shape of the output tensor.\n",
       "        Can be a variable number of arguments or a collection like a list or tuple.\n",
       "\n",
       "Keyword args:\n",
       "    generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
       "    out (Tensor, optional): the output tensor.\n",
       "    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
       "        Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
       "    layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
       "        Default: ``torch.strided``.\n",
       "    device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
       "        Default: if ``None``, uses the current device for the default tensor type\n",
       "        (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
       "        for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
       "    requires_grad (bool, optional): If autograd should record operations on the\n",
       "        returned tensor. Default: ``False``.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> torch.randn(4)\n",
       "    tensor([-2.1436,  0.9966,  2.3426, -0.6366])\n",
       "    >>> torch.randn(2, 3)\n",
       "    tensor([[ 1.5954,  2.8929, -1.0923],\n",
       "            [ 1.1719, -0.4709, -0.1996]])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.randn??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa519e-0975-4b59-a7ee-e25b5bbbaf45",
   "metadata": {},
   "source": [
    "PyTorch has [an interesting document entitled 'Reproducibility'](https://pytorch.org/docs/stable/notes/randomness.html) in which they state the things that you can try to do to make your code as non-deterministic (i.e. non-random) as possible. This is important if you want to be able to reproduce your work. At the top, however, and as I learned during the Sunday Delft FastAI Study Group discussion, it's not as simple as setting seed values; sometimes even the hardware used needs to be identical in order to achieve reproducibility:\n",
    "\n",
    "> \"Completely reproducible results are not guaranteed across PyTorch releases, individual commits, or different platforms. Furthermore, results may not be reproducible between CPU and GPU executions, even when using identical seeds.\"\n",
    "\n",
    "But why do we care about random values in deep learning to start with? We care because we are often doing things like augmentations in parallel. Augmentations are randomly generated, so if all the parallel processes use the same random number sequences then all the processes will generate the same augmented images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193a7222-d00c-44ab-b817-4de40e9a8668",
   "metadata": {},
   "source": [
    "We saw the nice example in the lesson of how our function runs into exactly this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d42a772-7e70-40cc-bd18-aa3a8d18b74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In parent: 0.17354408428968426\n",
      "In child: 0.17354408428968426\n"
     ]
    }
   ],
   "source": [
    "if os.fork():\n",
    "    print(f'In parent: {rand()}')\n",
    "else:\n",
    "    print(f'In child: {rand()}')\n",
    "    os._exit(os.EX_OK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c67ff4-f1fa-49d3-9f92-055429792e96",
   "metadata": {},
   "source": [
    "We create two forked processes, which are identical copies of each other. Then we call our pseudo-random number generator. You would expect that these two values would be different, but because we've copied the entire state then we get identical values. What we'd need to do is to set a new seed at the beginning of each process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6cf27d93-0355-45bb-87e1-bd8fa802f1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In parent: 0.01693090619965683\n",
      "In child: 0.02258025041320865\n"
     ]
    }
   ],
   "source": [
    "if os.fork():\n",
    "    seed(0)\n",
    "    print(f'In parent: {rand()}')\n",
    "else:\n",
    "    seed(1)\n",
    "    print(f'In child: {rand()}')\n",
    "    os._exit(os.EX_OK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3059da03-c65b-4ad6-a93e-de0aa10f40f1",
   "metadata": {},
   "source": [
    "# \"Things Jeremy says to do\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5e514-f496-49ea-a9b8-b7169eafe419",
   "metadata": {},
   "source": [
    "I thought I'd gather some of the core 'things Jeremy says to do' comments from the video lecture for this part of the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8ebf60-3465-4826-8145-519286616ec1",
   "metadata": {},
   "source": [
    "- show the function signature with `shift-Tab`\n",
    "- use `?` and `??` at the end of a method or function to show the docs and the source code respectively\n",
    "- read all the docs for every Python function you use\n",
    "    - look at all the arguments it takes\n",
    "    - practice with that function inside a notebook\n",
    "- (sometimes) read the full source code\n",
    "- pause the video when something in Jeremy's code is unfamiliar and experiment around with it in a notebook\n",
    "    - read the docs and example code for those new concepts\n",
    "- (at some point) read through all the docs for the `Tensor` object / concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab47524d-1be4-4327-90d1-3b44fe634739",
   "metadata": {},
   "source": [
    "Note that there's a bit more when it comes to the imagic demonstration which I'll try to cover in a separate blogpost.\n",
    "\n",
    "In any case, there was a lot in this lecture. This week is all about matrix multiplication which I'm looking forward to getting to implement myself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa7523-6d24-400c-bf69-e56f7fbbfb0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenml-testing2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, May 23 2022, 14:05:20) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "59ea241ca7da22c5404bcbb852ad4320b36fe5cff8b75f653e561d6b88a3302f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
