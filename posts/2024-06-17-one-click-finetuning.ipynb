{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "date: '2024-06-17'\n",
    "description: \"I tried out some services that promise to simplify the process of\n",
    "finetuning open models. I describe my experiences with Predibase, OpenPipe and OpenAI.\"\n",
    "output-file: 2024-06-17-one-click-finetuning.html\n",
    "title: \"One-click LLM finetuning with Predibase, OpenPipe and OpenAI\"\n",
    "image: 'images/one-click-finetuning.png'\n",
    "author: Alex Strick van Linschoten\n",
    "categories:\n",
    "  - nlp\n",
    "  - llms\n",
    "  - miniproject\n",
    "  - finetuning\n",
    "include-before-body: '<script defer data-domain=\"mlops.systems\" src=\"https://plausible.io/js/script.js\"></script>'\n",
    "toc: true\n",
    "layout: post\n",
    "comments:\n",
    "    utterances:\n",
    "        repo: strickvl/mlops-dot-systems\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [last post in this series](https://mlops.systems/posts/2024-06-15-isafpr-first-finetune.html) showed that finetuning an LLM needn't be\n",
    "particularly difficult. I used `axolotl` to produce finetuned versions of\n",
    "Llama3, Mistral and TinyLlama models. During the course we were given a bunch of\n",
    "credits by various companies in the LLM and finetuning space. Among those were\n",
    "credits from some finetuning-as-a-service companies and I thought now might be a\n",
    "good time to try out these services now that I've done the process manually a\n",
    "few times.\n",
    "\n",
    "I picked three to try out: Predibase, OpenPipe and OpenAI. All were surprisingly\n",
    "similar in the approach they took. I'll give a few details on the experience for\n",
    "each and how they compare to each other. With all the services, the process was\n",
    "roughly the same as when I did it manually:\n",
    "\n",
    "1. Upload custom data\n",
    "2. Select some hyperparameters\n",
    "3. Start the finetuning\n",
    "4. Try the model\n",
    "\n",
    "The step I had the most trouble with was the custom data upload, since each\n",
    "provider wanted the data in a different format. Converting the data from the\n",
    "Pydantic models I had previously created was not a huge deal, but I wasn't sure\n",
    "about the tradeoffs that I was making (or that were being made for me) by\n",
    "converting my data into these formats.\n",
    "\n",
    "## Predibase\n",
    "\n",
    "I started with [Predibase](https://predibase.com/) since I had enjoyed the talk\n",
    "Travis Addair had given during the course. Predibase is famous for their work on\n",
    "LORA adapters, particularly their demonstration of [Lora\n",
    "Land](https://predibase.com/blog/lora-land-fine-tuned-open-source-llms-that-outperform-gpt-4)\n",
    "where they gave some examples of how finetuned LORA models / adapters could\n",
    "outperform GPT-4.\n",
    "\n",
    "Predibase requires that the data you upload has certain column names depending\n",
    "on the task you select for the finetuning. At the moment they have instruction\n",
    "tuning and text completion as their two tasks, but it wasn't clear to me which\n",
    "to select. (They also have [a Colab notebook](https://colab.research.google.com/drive/1r505Aq_SWZdaSkBIs3ovh4F8c36DHwAh?usp=sharing) to help with constructing splits from your\n",
    "data.)\n",
    "\n",
    "Once your data is ready and validated, you can select the model you want to\n",
    "finetune along with a few other hyperparameters. This is the full extent of what\n",
    "you can set from the web UI:\n",
    "\n",
    "![Screenshot of Predibase website and the hyperparameters you can set](images/predibase-hyperparameters.png)\n",
    "\n",
    "There's also a helpful dataset preview pane to give a final sanity check for\n",
    "your data, to make sure that the inputs and outputs look what you'd expect:\n",
    "\n",
    "![Screenshot of Predibase website and the dataset preview\n",
    "pane](images/predibase-dataset-preview.png)\n",
    "\n",
    "As you'll read in a little bit, this feature helps catch potentially costly\n",
    "errors before you start the finetuning process.\n",
    "\n",
    "Once you click the button to start the training, there isn't a great deal of\n",
    "information available to you beyond (eventually) a loss curve that you can see.\n",
    "I chose to finetune Qwen2 in Predibase and this took about 53 minutes using an\n",
    "A-100 GPU accelerator.\n",
    "\n",
    "Once your model is ready, you can prompt the model in the UI, or using their\n",
    "REST API / Python SDK. They give code snippets prefilled with some dummy text\n",
    "that you can easily try out locally. Let's show that here, but before you can\n",
    "run your inference query you have to first deploy the model. I hadn't expected\n",
    "this extra step, and it takes a while to spin up since it's deploying the\n",
    "adaptor along with the base model it was finetuned alongside. My Qwen2 model has\n",
    "a context window of 131072 tokens and supposedly would cost $3.90 per hour that\n",
    "it was up (as a dedicated deployment).\n",
    "\n",
    "Let's show the results we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1 = \"\"\"2011-11-S-011 ISAF Joint Command - Afghanistan For Immediate Release\n",
    "      KABUL, Afghanistan (Nov. 7, 2011) â€” A combined Afghan and coalition\n",
    "      security force conducted an operation in search of a Haqqani facilitator\n",
    "      in Argo district, Badakshan province. The facilitator coordinates suicide\n",
    "      attacks with other insurgent leaders in the area. During the operation, a\n",
    "      local national male failed to comply with repeated verbal warnings and\n",
    "      displayed hostile intent toward the security force. The security force\n",
    "      engaged the individual, resulting in his death. The security force\n",
    "      confiscated a shotgun and intelligence linking the local national to the\n",
    "      Haqqani network. The security force also detained two suspected insurgents during the operation.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"You are an expert at identifying events in a press release. You are precise and always make sure you are correct, drawing inference from the text of the press release. event_types = ['airstrike', 'detention', 'captureandkill', 'insurgentskilled', 'exchangeoffire', 'civiliancasualty'], provinces = ['badakhshan', 'badghis', 'baghlan', 'balkh', 'bamyan', 'day_kundi', 'farah', 'faryab', 'ghazni', 'ghor', 'helmand', 'herat', 'jowzjan', 'kabul', 'kandahar', 'kapisa', 'khost', 'kunar', 'kunduz', 'laghman', 'logar', 'nangarhar', 'nimroz', 'nuristan', 'paktya', 'paktika', 'panjshir', 'parwan', 'samangan', 'sar_e_pul', 'takhar', 'uruzgan', 'wardak', 'zabul'], target_groups = ['taliban', 'haqqani', 'criminals', 'aq', 'hig', 'let', 'imu', 'judq', 'iju', 'hik', 'ttp', 'other']\n",
    "\n",
    "### Instruction:\n",
    "\n",
    "PRESS RELEASE TEXT: '{pr1}'\n",
    "\n",
    "### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from predibase import Predibase\n",
    "\n",
    "pb = Predibase(api_token=os.getenv(\"PREDIBASE_API_KEY\"))\n",
    "# pb = Predibase(api_token=\"\")\n",
    "\n",
    "lorax_client = pb.deployments.client(\"isafpr\")\n",
    "print(lorax_client.generate(prompt, max_new_tokens=100).generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOME TEXT GOES HERE\n",
    "\n",
    "## OpenAI\n",
    "\n",
    "I was actually surprised that this is even a thing that people do or that is\n",
    "offered by OpenAI. Currently you're able to finetune three versions of GPT3.5 as\n",
    "well as `babbage-002` and `davinci-002`. In the OpenAI presentation during the\n",
    "course they mentioned that they were working to make it possible to finetune\n",
    "GPT4 as well, but no timeline was given on this.\n",
    "\n",
    "So why would someone want to finetune GPT3.5? I think there are some problems\n",
    "that are sufficiently complex or of a specific nature where the OpenAI GPT\n",
    "family shines where you might want to squeeze out a final last bit of\n",
    "performance and where the open LLMs just aren't there yet.\n",
    "\n",
    "The OpenAI models are sort of the antithesis of an\n",
    "'open' model and nothing about the finetuning process lent itself to disabusing\n",
    "you of that idea. This was the UI to fill in in order to finetune a model and as\n",
    "you can see there aren't really too many options available to you.\n",
    "\n",
    "![OpenAI Finetuning UI](/images/openai-finetuning-ui.png)\n",
    "\n",
    "Supposedly the data you upload (options for train as well as a separate test set\n",
    "here) will never be used by OpenAI to train their models but you have to just\n",
    "trust them on that front.\n",
    "\n",
    "![UI medatada during finetuning 1](/images/openai-finetuning-ui-2.png)\n",
    "![UI medatada during finetuning 2](/images/openai-finetuning-ui-3.png)\n",
    "\n",
    "As with Predibase, during finetuning you don't have access to any logs or even\n",
    "too much feedback during training. You get a loss curve and a few scraps of\n",
    "metadata and that's it. The training took around 90 minutes to run and then\n",
    "you're able to prompt the model to see how it works, using the standard OpenAI\n",
    "interface and methods you're used to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'start_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2011-11-07'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'event_type'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'captureandkill'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'province'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'badakhshan'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'target_group'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'haqqani'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'min_killed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'min_captured'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'killq'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'captureq'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'killcaptureraid'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'airstrike'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'noshotsfired'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'min_leaders_killed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'min_leaders_captured'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'name'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "    \u001b[32m'start_date'\u001b[0m: \u001b[32m'2011-11-07'\u001b[0m,\n",
       "    \u001b[32m'event_type'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'captureandkill'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'province'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'badakhshan'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'target_group'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'haqqani'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'min_killed'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'min_captured'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "    \u001b[32m'killq'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'captureq'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'killcaptureraid'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'airstrike'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'noshotsfired'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'min_leaders_killed'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'min_leaders_captured'\u001b[0m: \u001b[1;36m0\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from rich import print\n",
    "import json\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"ft:gpt-3.5-turbo-SOME_EXTRA_STUFF_HERE_FOR_MY_MODEL\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert at identifying events in a press release. You are precise and always make sure you are correct, drawing inference from the text of the press release. event_types = ['airstrike', 'detention', 'captureandkill', 'insurgentskilled', 'exchangeoffire', 'civiliancasualty'], provinces = ['badakhshan', 'badghis', 'baghlan', 'balkh', 'bamyan', 'day_kundi', 'farah', 'faryab', 'ghazni', 'ghor', 'helmand', 'herat', 'jowzjan', 'kabul', 'kandahar', 'kapisa', 'khost', 'kunar', 'kunduz', 'laghman', 'logar', 'nangarhar', 'nimroz', 'nuristan', 'paktya', 'paktika', 'panjshir', 'parwan', 'samangan', 'sar_e_pul', 'takhar', 'uruzgan', 'wardak', 'zabul'], target_groups = ['taliban', 'haqqani', 'criminals', 'aq', 'hig', 'let', 'imu', 'judq', 'iju', 'hik', 'ttp', 'other'].\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": pr1\n",
    "        }\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(json.loads(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They also give you an interface to see the response of the base model\n",
    "side-by-side against the finetuned model:\n",
    "\n",
    "![Side-by-side UI of base model and finetuned model inference](/images/openai-finetuning-ui-4.png)\n",
    "\n",
    "As you can see, it's done pretty well! It stuck to the JSON structure, and the\n",
    "extracted metadata looks good. Of course, since this is a GPT3.5 model, there's\n",
    "no way to now download this model and run it locally. You're hostage to OpenAI,\n",
    "to being online, etc etc. Not a scenario I'd like to be in, so I don't think\n",
    "I'll pursue this much further and rather use my OpenAI credits for other\n",
    "purposes.\n",
    "\n",
    "All that said, I do think there might be some scenarios where only the OpenAI\n",
    "models are reliable enough to use (be that in terms of accuracy or with\n",
    "sufficient guardrails) and there were people in the course who were in this\n",
    "boat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openpipe\n",
    "\n",
    "from openpipe import OpenAI\n",
    "from rich import print\n",
    "import json\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "  openpipe={\"api_key\": os.getenv(\"OPENPIPE_API_KEY\")}\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"openpipe:fine-steaks-taste\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert at identifying events in a press release. You are precise and always make sure you are correct, drawing inference from the text of the press release. event_types = ['airstrike', 'detention', 'captureandkill', 'insurgentskilled', 'exchangeoffire', 'civiliancasualty'], provinces = ['badakhshan', 'badghis', 'baghlan', 'balkh', 'bamyan', 'day_kundi', 'farah', 'faryab', 'ghazni', 'ghor', 'helmand', 'herat', 'jowzjan', 'kabul', 'kandahar', 'kapisa', 'khost', 'kunar', 'kunduz', 'laghman', 'logar', 'nangarhar', 'nimroz', 'nuristan', 'paktya', 'paktika', 'panjshir', 'parwan', 'samangan', 'sar_e_pul', 'takhar', 'uruzgan', 'wardak', 'zabul'], target_groups = ['taliban', 'haqqani', 'criminals', 'aq', 'hig', 'let', 'imu', 'judq', 'iju', 'hik', 'ttp', 'other'].\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": pr1\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    "    openpipe={\n",
    "        \"tags\": {\n",
    "            \"prompt_id\": \"counting\",\n",
    "            \"any_key\": \"any_value\"\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "print(json.loads(completion.choices[0].message.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isafpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
